{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "zWzj1-XWrnE0",
   "metadata": {
    "id": "zWzj1-XWrnE0"
   },
   "source": [
    "# 0. 패키지 불러오기 및 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rXsH1aGL8u0-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 119297,
     "status": "ok",
     "timestamp": 1669475935855,
     "user": {
      "displayName": "신웅재",
      "userId": "08301511488967665306"
     },
     "user_tz": -540
    },
    "id": "rXsH1aGL8u0-",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "4a8ded32-8e7d-4f38-a004-5f1ce6a458af",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.1.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from catboost) (1.5.1)\n",
      "Requirement already satisfied: plotly in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from catboost) (5.11.0)\n",
      "Requirement already satisfied: six in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from catboost) (3.6.2)\n",
      "Requirement already satisfied: graphviz in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from catboost) (1.20.3)\n",
      "Requirement already satisfied: scipy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from catboost) (1.8.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas>=0.24.0->catboost) (2022.6)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->catboost) (1.0.6)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->catboost) (4.38.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->catboost) (9.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from plotly->catboost) (8.1.0)\n",
      "Requirement already satisfied: category_encoders in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (2.5.1.post0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from category_encoders) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from category_encoders) (0.23.2)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from category_encoders) (1.5.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from category_encoders) (0.13.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from category_encoders) (1.8.1)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from category_encoders) (0.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas>=1.0.5->category_encoders) (2022.6)\n",
      "Requirement already satisfied: six in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from statsmodels>=0.9.0->category_encoders) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from packaging>=21.3->statsmodels>=0.9.0->category_encoders) (3.0.9)\n",
      "Requirement already satisfied: lightgbm in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (3.3.3)\n",
      "Requirement already satisfied: scipy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from lightgbm) (1.8.1)\n",
      "Requirement already satisfied: numpy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from lightgbm) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: wheel in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j5Gvu4xG7hER",
   "metadata": {
    "id": "j5Gvu4xG7hER"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "import math\n",
    "\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor, RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor, HistGradientBoostingClassifier, HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, KFold # KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, f1_score, confusion_matrix \n",
    "# make_scorer : MSE 대신 사용자가 정의한 손실함수를 사용하고 싶을 때\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from sklearn.svm import * # SVC, SVR\n",
    "# from sklearn.inspection import *\n",
    "# from sklearn.linear_model import * # LogisticRegression, RANSACRegressor, Ridge, Lasso, ElasticNet\n",
    "# from sklearn.decomposition import * # PCA\n",
    "\n",
    "# from category_encoders.ordinal import OrdinalEncoder\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "# from sklearn.cluster import KMeans\n",
    "# from kmodes.kmodes import KModes\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "# from pycaret.classification import *\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "# import xgboost as xgb\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore') # 경고메세지를 무시하거나 숨긴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc8vGBU5qcR8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "executionInfo": {
     "elapsed": 942,
     "status": "ok",
     "timestamp": 1669476088940,
     "user": {
      "displayName": "신웅재",
      "userId": "08301511488967665306"
     },
     "user_tz": -540
    },
    "id": "dc8vGBU5qcR8",
    "outputId": "a8774e9a-874d-45ec-9c34-b333cc36b52b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095, 54)\n",
      "761130\n",
      "(6041, 19)\n",
      "114779\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>COMPONENT_ARBITRARY</th>\n",
       "      <th>ANONYMOUS_1</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>SAMPLE_TRANSFER_DAY</th>\n",
       "      <th>ANONYMOUS_2</th>\n",
       "      <th>AG</th>\n",
       "      <th>AL</th>\n",
       "      <th>B</th>\n",
       "      <th>BA</th>\n",
       "      <th>...</th>\n",
       "      <th>U25</th>\n",
       "      <th>U20</th>\n",
       "      <th>U14</th>\n",
       "      <th>U6</th>\n",
       "      <th>U4</th>\n",
       "      <th>V</th>\n",
       "      <th>V100</th>\n",
       "      <th>V40</th>\n",
       "      <th>ZN</th>\n",
       "      <th>Y_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_00000</td>\n",
       "      <td>COMPONENT3</td>\n",
       "      <td>1486</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00001</td>\n",
       "      <td>COMPONENT2</td>\n",
       "      <td>1350</td>\n",
       "      <td>2021</td>\n",
       "      <td>51</td>\n",
       "      <td>375</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>652</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00002</td>\n",
       "      <td>COMPONENT2</td>\n",
       "      <td>2415</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11261.0</td>\n",
       "      <td>41081.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.6</td>\n",
       "      <td>412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_00003</td>\n",
       "      <td>COMPONENT3</td>\n",
       "      <td>7389</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_00004</td>\n",
       "      <td>COMPONENT3</td>\n",
       "      <td>3954</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID COMPONENT_ARBITRARY  ANONYMOUS_1  YEAR  SAMPLE_TRANSFER_DAY  \\\n",
       "0  TRAIN_00000          COMPONENT3         1486  2011                    7   \n",
       "1  TRAIN_00001          COMPONENT2         1350  2021                   51   \n",
       "2  TRAIN_00002          COMPONENT2         2415  2015                    2   \n",
       "3  TRAIN_00003          COMPONENT3         7389  2010                    2   \n",
       "4  TRAIN_00004          COMPONENT3         3954  2015                    4   \n",
       "\n",
       "   ANONYMOUS_2  AG   AL    B  BA  ...  U25  U20   U14       U6       U4  V  \\\n",
       "0          200   0    3   93   0  ...  NaN  NaN   NaN      NaN      NaN  0   \n",
       "1          375   0    2   19   0  ...  2.0  4.0   6.0    216.0   1454.0  0   \n",
       "2          200   0  110    1   1  ...  0.0  3.0  39.0  11261.0  41081.0  0   \n",
       "3          200   0    8    3   0  ...  NaN  NaN   NaN      NaN      NaN  0   \n",
       "4          200   0    1  157   0  ...  NaN  NaN   NaN      NaN      NaN  0   \n",
       "\n",
       "   V100    V40   ZN  Y_LABEL  \n",
       "0   NaN  154.0   75        0  \n",
       "1   NaN   44.0  652        0  \n",
       "2   NaN   72.6  412        1  \n",
       "3   NaN  133.3    7        0  \n",
       "4   NaN  133.1  128        0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/studio-lab-user/MYDATA/Construction Machine Oil/open/'\n",
    "\n",
    "Rdata_train = pd.read_csv(path + 'train.csv')\n",
    "Rdata_test = pd.read_csv(path + 'test.csv')\n",
    "\n",
    "print(Rdata_train.shape) # (14095, 54) -> 생각보다 데이터 수가 적다.\n",
    "print(Rdata_train.size)\n",
    "print(Rdata_test.shape) # (6041, 19)\n",
    "print(Rdata_test.size)\n",
    "Rdata_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xDZioui9emZl",
   "metadata": {
    "id": "xDZioui9emZl"
   },
   "source": [
    "# 1. CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-C-94ErPVNBb",
   "metadata": {
    "id": "-C-94ErPVNBb"
   },
   "source": [
    "new_var_set = ['FOPTIMETHGLY', 'FE', 'ZN', 'NI', 'BA', \n",
    "               'FNOX', 'CR', 'SI', 'CA', 'U75', \n",
    "               'K', 'SN', 'AL', 'V40', 'NA', \n",
    "               'FH2O', 'U4', 'ANONYMOUS_1', 'S', 'SB', \n",
    "               'FTBN', 'CU', 'B', 'PQINDEX', 'ANONYMOUS_2',\n",
    "               'COMPONENT_ARBITRARY', 'YEAR']  \n",
    "주 변수 -> 'COMPONENT_ARBITRARY', 'ANONYMOUS_1', 'YEAR', 'ANONYMOUS_2', 'CR', 'CU', 'FE', 'NI', 'PQINDEX', 'V40', 'ZN' -> 11개  \n",
    "부 변수(결측 없음) -> 'BA', 'SI', 'CA', 'SN', 'AL', 'NA', 'S', 'SB', 'B' -> 9개  \n",
    "부 별수(결측 있음) -> 'FH2O', 'FNOX', 'FOPTIMETHGLY', 'FTBN', 'K', 'U75', 'U4' -> 7개  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7CIWT2P-emZm",
   "metadata": {
    "id": "7CIWT2P-emZm"
   },
   "outputs": [],
   "source": [
    "train1 = Rdata_train.copy()\n",
    "test1 = Rdata_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "GWGsZlUSemZm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1669476096295,
     "user": {
      "displayName": "신웅재",
      "userId": "08301511488967665306"
     },
     "user_tz": -540
    },
    "id": "GWGsZlUSemZm",
    "outputId": "d6ab0ac2-8d63-49c3-b1af-ec9c8debacdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095, 21)\n",
      "(6041, 18)\n"
     ]
    }
   ],
   "source": [
    "# AL과 BA만 추가하여 MODEL1을 만들자.\n",
    "train2 = train1.loc[:, ['COMPONENT_ARBITRARY', 'ANONYMOUS_1', 'YEAR', 'ANONYMOUS_2', 'AG',\n",
    "                                        'CO', 'CR', 'CU', 'FE', 'H2O', 'MN', 'MO', 'NI', 'PQINDEX', 'TI', 'V',\n",
    "                                        'V40', 'ZN', 'Y_LABEL', 'AL', 'BA']]\n",
    "test2 = test1.drop(['ID'], axis = 1)\n",
    "\n",
    "print(train2.shape) # 변수 20개\n",
    "print(test2.shape) # 변수 18개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6R6-BeqKemZm",
   "metadata": {
    "id": "6R6-BeqKemZm"
   },
   "outputs": [],
   "source": [
    "# 이 작업을 수행하면 범주형 변수인 COMPONENT_ARBITRARY와 YEAR를 숫자로 바꿔준다.\n",
    "# 단 OneHotEncoder가 아님, 내가 쓴건 LabelEncoder\n",
    "# OneHotEncoder -> 개 : 1 0 0, 고양이 : 0 1 0, 사자 : 0 0 1\n",
    "# LabelEncoder -> 개 : 0, 고양이 : 1, 사자 : 2\n",
    "\n",
    "le1 = LabelEncoder()\n",
    "le2 = LabelEncoder()\n",
    "\n",
    "train2['COMPONENT_ARBITRARY_category'] = le1.fit_transform(train2['COMPONENT_ARBITRARY'])\n",
    "train2['YEAR_category'] = le2.fit_transform(train2['YEAR'])\n",
    "\n",
    "test2['COMPONENT_ARBITRARY_category'] = le1.transform(test2['COMPONENT_ARBITRARY'])\n",
    "test2['YEAR_category'] = le2.transform(test2['YEAR'])\n",
    "\n",
    "# 원래 범주형 변수는 제거해준다.\n",
    "train3 = train2.drop(['COMPONENT_ARBITRARY', 'YEAR'], axis = 1)\n",
    "test3 = test2.drop(['COMPONENT_ARBITRARY', 'YEAR'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e6MyR14EemZm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1669476100211,
     "user": {
      "displayName": "신웅재",
      "userId": "08301511488967665306"
     },
     "user_tz": -540
    },
    "id": "e6MyR14EemZm",
    "outputId": "df10aa45-7acd-4067-e45c-4582a72011de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095, 21)\n",
      "(6041, 18)\n"
     ]
    }
   ],
   "source": [
    "# 범주형 변수와 숫자형 변수를 나눠준다.\n",
    "categorical_features = ['COMPONENT_ARBITRARY_category', 'YEAR_category']\n",
    "# numeric_features_train = ['ANONYMOUS_1', 'ANONYMOUS_2', 'AG', 'CO', 'CR', 'CU', \n",
    "#                     'FE', 'H2O', 'MN', 'MO', 'NI', 'PQINDEX', 'TI', 'V', 'V40', 'ZN', 'AL', 'BA']\n",
    "# numeric_features_test = ['ANONYMOUS_1', 'ANONYMOUS_2', 'AG', 'CO', 'CR', 'CU', \n",
    "#                     'FE', 'H2O', 'MN', 'MO', 'NI', 'PQINDEX', 'TI', 'V', 'V40', 'ZN']\n",
    "\n",
    "print(train3.shape)\n",
    "print(test3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "UJJUrj_BZYDL",
   "metadata": {
    "id": "UJJUrj_BZYDL"
   },
   "outputs": [],
   "source": [
    "X_train = train3.drop(['Y_LABEL'], axis = 1)\n",
    "y_train = train3['Y_LABEL']\n",
    "X_test = test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6YEw_EFuZHLH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1669476103113,
     "user": {
      "displayName": "신웅재",
      "userId": "08301511488967665306"
     },
     "user_tz": -540
    },
    "id": "6YEw_EFuZHLH",
    "outputId": "7c258843-ee20-413f-fee0-ec507fe96bfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9866, 20)\n",
      "(4229, 20)\n",
      "(9866,)\n",
      "(4229,)\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증을 위해 train데이터를 partrain과 val로 나눠준다.\n",
    "\n",
    "X_partrain, X_val, y_partrain, y_val = train_test_split(X_train, y_train, test_size = 0.3, random_state = 39, stratify = y_train)\n",
    "print(X_partrain.shape)\n",
    "print(X_val.shape)\n",
    "print(y_partrain.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "vNvhdKWuemZm",
   "metadata": {
    "id": "vNvhdKWuemZm"
   },
   "outputs": [],
   "source": [
    "# 교차검증 패키지인 optuna 사용을 한다.\n",
    "# 이 작업은 어떤 초모수일때, 모델이 가장 좋은지 적합해준다.\n",
    "\n",
    "def objective(trial : Trial) -> float :\n",
    "\n",
    "    params_cat = {\n",
    "        \"random_state\" : 39,\n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.001, 1), # 학습률이 0.005와 0.5 사이의 랜덤한 값으로 정해줌\n",
    "        \"n_estimators\" : trial.suggest_int(\"n_estimators\", 100, 1000), # 400과 1000 사이에 랜덤한 값으로 정해줌\n",
    "        \"max_depth\" : trial.suggest_int(\"max_depth\", 3, 16) # 3과 10 사이에 랜덤한 값으로 정해줌\n",
    "  }\n",
    "    \n",
    "    model = CatBoostClassifier(**params_cat) # Catboost가 AutoML에서 가장 좋아서 Catboost로 했다.\n",
    "    model.fit(X_partrain, y_partrain, eval_set = [(X_val, y_val)],\n",
    "              early_stopping_rounds = 100, cat_features = categorical_features, verbose = False)\n",
    "\n",
    "    cat_pred = model.predict(X_val)\n",
    "    AUC = roc_auc_score(y_val, cat_pred)\n",
    "    \n",
    "    return AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "pPlPtmj_emZm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3075232,
     "status": "ok",
     "timestamp": 1669125004750,
     "user": {
      "displayName": "신웅재",
      "userId": "08301511488967665306"
     },
     "user_tz": -540
    },
    "id": "pPlPtmj_emZm",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "ec8fc0f8-8523-4197-ac3f-0f4107bd744d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-10 12:00:05,513]\u001b[0m A new study created in memory with name: cat_parameter_opt\u001b[0m\n",
      "\u001b[33m[W 2022-12-10 12:00:10,014]\u001b[0m Trial 0 failed because of the following error: KeyboardInterrupt('')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_174/1687905101.py\", line 14, in objective\n",
      "    model.fit(X_partrain, y_partrain, eval_set = [(X_val, y_val)],\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/catboost/core.py\", line 5128, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/catboost/core.py\", line 2355, in _fit\n",
      "    self._train(\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/catboost/core.py\", line 1759, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4623, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4672, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_174/2364783162.py\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     sampler = sampler)\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \"\"\"\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    420\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     ):\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_174/1687905101.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams_cat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Catboost가 AutoML에서 가장 좋아서 Catboost로 했다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     model.fit(X_partrain, y_partrain, eval_set = [(X_val, y_val)],\n\u001b[0m\u001b[1;32m     15\u001b[0m               early_stopping_rounds = 100, cat_features = categorical_features, verbose = False)\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5126\u001b[0m             \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5128\u001b[0;31m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0m\u001b[1;32m   5129\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5130\u001b[0m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2353\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_cout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_cerr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m             \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Training plots'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2355\u001b[0;31m             self._train(\n\u001b[0m\u001b[1;32m   2356\u001b[0m                 \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2357\u001b[0m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_sets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 이 작업을 해주면 어떤 초모수가 가장 좋은지를 얘가 판단을 해준다.\n",
    "# 나는 총 100번 돌렸지만, 원래는 1000번 정도 돌리는게 좋다.\n",
    "\n",
    "sampler = TPESampler(seed = 39)\n",
    "study = optuna.create_study(\n",
    "    study_name = \"cat_parameter_opt\",\n",
    "    direction = \"maximize\",\n",
    "    sampler = sampler)\n",
    "study.optimize(objective, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y_HuSV4uemZn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1669125049718,
     "user": {
      "displayName": "신웅재",
      "userId": "08301511488967665306"
     },
     "user_tz": -540
    },
    "id": "Y_HuSV4uemZn",
    "outputId": "3b630ddc-6a15-4025-8cfc-132fb402c823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score : 0.7665005428446204\n",
      "Best trial : {'learning_rate': 0.03142344166841527, 'n_estimators': 513, 'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "# 가장 좋은 초모수를 알려준다. \n",
    "\n",
    "print(\"Best Score :\", study.best_value)\n",
    "print(\"Best trial :\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ahdiMMnCemZn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54945,
     "status": "ok",
     "timestamp": 1669125653409,
     "user": {
      "displayName": "신웅재",
      "userId": "08301511488967665306"
     },
     "user_tz": -540
    },
    "id": "ahdiMMnCemZn",
    "outputId": "94fee6ea-82be-491b-8a5c-96400b5fcf18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095, 2)\n",
      "(9866, 2)\n",
      "training model for CV #1\n",
      "training model for CV #2\n",
      "training model for CV #3\n",
      "training model for CV #4\n",
      "training model for CV #5\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증해서 얻은 초모수를 가지고 train 데이터의 예측 불량률을 파악한다.\n",
    "\n",
    "n_fold = 5\n",
    "cv = StratifiedKFold(n_splits = n_fold, shuffle = True, random_state = 39)\n",
    "\n",
    "cat_val = np.zeros((X_train.shape[0], 2))\n",
    "cat_partrain = np.zeros((X_partrain.shape[0], 2))\n",
    "\n",
    "print(cat_val.shape)\n",
    "print(cat_partrain.shape)\n",
    "\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(X_train, y_train), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    optuna_cat = CatBoostClassifier(\n",
    "        random_state = 39,\n",
    "        learning_rate = 0.03142344166841527, \n",
    "        n_estimators = 513, \n",
    "        max_depth = 6)\n",
    "\n",
    "    optuna_cat.fit(X_train.loc[i_trn, :], y_train[i_trn], verbose = False, \n",
    "                   cat_features = categorical_features, early_stopping_rounds = 100)\n",
    "\n",
    "    cat_val[i_val, :] = optuna_cat.predict_proba(X_train.loc[i_val, :])\n",
    "    cat_partrain += optuna_cat.predict_proba(X_partrain) / n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "Yu4y86fWemZn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1669126085371,
     "user": {
      "displayName": "신웅재",
      "userId": "08301511488967665306"
     },
     "user_tz": -540
    },
    "id": "Yu4y86fWemZn",
    "outputId": "c0f40a65-aa1b-48f2-9c30-e6b032f3d977"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095, 2)\n",
      "(9866, 2)\n",
      "(14095, 22)\n"
     ]
    }
   ],
   "source": [
    "# 정상률 말고 불량률만 train 데이터에 따로 붙여서 train 데이터의 변수는 총 22개로 늘어났다.\n",
    "\n",
    "print(cat_val.shape)\n",
    "print(cat_partrain.shape)\n",
    "\n",
    "train_teacher = train3.copy()\n",
    "\n",
    "train_teacher['Cat_prob1'] = cat_val[:, 1]\n",
    "print(train_teacher.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PQB9KsuPptb-",
   "metadata": {
    "id": "PQB9KsuPptb-"
   },
   "source": [
    "# 2. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "61c75167-cb18-4f2f-a1cb-1f267cdf7d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9866, 20)\n",
      "(4229, 20)\n",
      "(9866,)\n",
      "(4229,)\n"
     ]
    }
   ],
   "source": [
    "train1 = Rdata_train.copy()\n",
    "test1 = Rdata_test.copy()\n",
    "\n",
    "train2 = train1.loc[:, ['COMPONENT_ARBITRARY', 'ANONYMOUS_1', 'YEAR', 'ANONYMOUS_2', 'AG',\n",
    "                                        'CO', 'CR', 'CU', 'FE', 'H2O', 'MN', 'MO', 'NI', 'PQINDEX', 'TI', 'V',\n",
    "                                        'V40', 'ZN', 'Y_LABEL', 'AL', 'BA']]\n",
    "test2 = test1.drop(['ID'], axis = 1)\n",
    "\n",
    "le1 = LabelEncoder()\n",
    "le2 = LabelEncoder()\n",
    "\n",
    "train2['COMPONENT_ARBITRARY_category'] = le1.fit_transform(train2['COMPONENT_ARBITRARY'])\n",
    "train2['YEAR_category'] = le2.fit_transform(train2['YEAR'])\n",
    "\n",
    "test2['COMPONENT_ARBITRARY_category'] = le1.transform(test2['COMPONENT_ARBITRARY'])\n",
    "test2['YEAR_category'] = le2.transform(test2['YEAR'])\n",
    "\n",
    "train3 = train2.drop(['COMPONENT_ARBITRARY', 'YEAR'], axis = 1)\n",
    "test3 = test2.drop(['COMPONENT_ARBITRARY', 'YEAR'], axis = 1)\n",
    "\n",
    "categorical_features = ['COMPONENT_ARBITRARY_category', 'YEAR_category']\n",
    "\n",
    "X_train = train3.drop(['Y_LABEL'], axis = 1)\n",
    "y_train = train3['Y_LABEL']\n",
    "X_test = test3\n",
    "\n",
    "X_partrain, X_val, y_partrain, y_val = train_test_split(X_train, y_train, test_size = 0.3, random_state = 39, stratify = y_train)\n",
    "print(X_partrain.shape)\n",
    "print(X_val.shape)\n",
    "print(y_partrain.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bbff9bae-1f03-40eb-9273-7e4f02e52383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial : Trial) -> float :\n",
    "\n",
    "    params_lgb = {\n",
    "        \"random_state\" : 39,\n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.001, 1),\n",
    "        \"n_estimators\" : trial.suggest_int(\"n_estimators\", 100, 1000), \n",
    "        \"max_depth\" : trial.suggest_int(\"max_depth\", 3, 16),\n",
    "        'reg_alpha' : trial.suggest_loguniform('reg_alpha', 0.001, 1),\n",
    "        'reg_lambda' : trial.suggest_loguniform('reg_lambda', 0.001, 1)\n",
    "        \n",
    "    }\n",
    "    \n",
    "    model = lgb.LGBMClassifier(**params_lgb)\n",
    "    model.fit(X_partrain, y_partrain, eval_set = [(X_val, y_val)],\n",
    "              early_stopping_rounds = 100, verbose = False)\n",
    "\n",
    "    lgb_pred = model.predict(X_val)\n",
    "    AUC = roc_auc_score(y_val, lgb_pred)\n",
    "    \n",
    "    return AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6166b3be-6217-47eb-ba84-3a123b2a8207",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-10 13:52:21,822]\u001b[0m A new study created in memory with name: lgb_parameter_opt\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:22,263]\u001b[0m Trial 0 finished with value: 0.7652447670637978 and parameters: {'learning_rate': 0.04371872304807245, 'n_estimators': 818, 'max_depth': 14, 'reg_alpha': 0.002323537042351288, 'reg_lambda': 0.0639743703819749}. Best is trial 0 with value: 0.7652447670637978.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:22,656]\u001b[0m Trial 1 finished with value: 0.7641182570533993 and parameters: {'learning_rate': 0.03771757391455586, 'n_estimators': 517, 'max_depth': 9, 'reg_alpha': 0.07909308741230786, 'reg_lambda': 0.5984000779343428}. Best is trial 0 with value: 0.7652447670637978.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:22,882]\u001b[0m Trial 2 finished with value: 0.7658542139925004 and parameters: {'learning_rate': 0.27958170383769165, 'n_estimators': 950, 'max_depth': 15, 'reg_alpha': 0.017558701225637952, 'reg_lambda': 0.30021741896396037}. Best is trial 2 with value: 0.7658542139925004.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:23,057]\u001b[0m Trial 3 finished with value: 0.7426963049325813 and parameters: {'learning_rate': 0.68989080483343, 'n_estimators': 665, 'max_depth': 6, 'reg_alpha': 0.05984842261391979, 'reg_lambda': 0.3812513877805805}. Best is trial 2 with value: 0.7658542139925004.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:24,955]\u001b[0m Trial 4 finished with value: 0.758707356618837 and parameters: {'learning_rate': 0.001397517628649231, 'n_estimators': 870, 'max_depth': 13, 'reg_alpha': 0.007725388176354637, 'reg_lambda': 0.028590346350381008}. Best is trial 2 with value: 0.7658542139925004.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:25,107]\u001b[0m Trial 5 finished with value: 0.7667590743854684 and parameters: {'learning_rate': 0.3410566280907551, 'n_estimators': 642, 'max_depth': 5, 'reg_alpha': 0.03787099728554101, 'reg_lambda': 0.003654195005146744}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:25,306]\u001b[0m Trial 6 finished with value: 0.7643767885942473 and parameters: {'learning_rate': 0.10264575982813771, 'n_estimators': 594, 'max_depth': 5, 'reg_alpha': 0.6273193963630301, 'reg_lambda': 0.04254610061439908}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:25,607]\u001b[0m Trial 7 finished with value: 0.7639889912829753 and parameters: {'learning_rate': 0.09071345093703738, 'n_estimators': 704, 'max_depth': 14, 'reg_alpha': 0.0010981867456912866, 'reg_lambda': 0.3495701519742112}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:26,246]\u001b[0m Trial 8 finished with value: 0.7639889912829753 and parameters: {'learning_rate': 0.020193688327597187, 'n_estimators': 530, 'max_depth': 13, 'reg_alpha': 0.33156910035218085, 'reg_lambda': 0.0021865477587311396}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:26,414]\u001b[0m Trial 9 finished with value: 0.7613481739509061 and parameters: {'learning_rate': 0.0687205460798068, 'n_estimators': 299, 'max_depth': 3, 'reg_alpha': 0.006949773590098959, 'reg_lambda': 0.0076025410779310245}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:26,721]\u001b[0m Trial 10 finished with value: 0.7392243910543791 and parameters: {'learning_rate': 0.004873278660942365, 'n_estimators': 133, 'max_depth': 9, 'reg_alpha': 0.15683405166616982, 'reg_lambda': 0.0011897447953364056}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:26,955]\u001b[0m Trial 11 finished with value: 0.7599448704764142 and parameters: {'learning_rate': 0.720893896309025, 'n_estimators': 951, 'max_depth': 16, 'reg_alpha': 0.01752622045553829, 'reg_lambda': 0.007129645030502635}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:27,171]\u001b[0m Trial 12 finished with value: 0.7634719282012793 and parameters: {'learning_rate': 0.2746827745641626, 'n_estimators': 985, 'max_depth': 7, 'reg_alpha': 0.023777349803222214, 'reg_lambda': 0.127368178952336}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:27,415]\u001b[0m Trial 13 finished with value: 0.7580610277667171 and parameters: {'learning_rate': 0.24682205634742246, 'n_estimators': 413, 'max_depth': 11, 'reg_alpha': 0.010689714185763304, 'reg_lambda': 0.012902578181860008}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:27,536]\u001b[0m Trial 14 finished with value: 0.7639889912829753 and parameters: {'learning_rate': 0.2952671663583295, 'n_estimators': 752, 'max_depth': 3, 'reg_alpha': 0.04652582093686467, 'reg_lambda': 0.15463347293131677}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:28,335]\u001b[0m Trial 15 finished with value: 0.7639889912829753 and parameters: {'learning_rate': 0.01314503054687319, 'n_estimators': 370, 'max_depth': 11, 'reg_alpha': 0.003793061472682141, 'reg_lambda': 0.003069561540584731}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:28,563]\u001b[0m Trial 16 finished with value: 0.7622161524204568 and parameters: {'learning_rate': 0.1545539022979192, 'n_estimators': 868, 'max_depth': 7, 'reg_alpha': 0.12299638852745973, 'reg_lambda': 0.017266594664582212}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:28,803]\u001b[0m Trial 17 finished with value: 0.7579135000730477 and parameters: {'learning_rate': 0.8561873032148485, 'n_estimators': 164, 'max_depth': 16, 'reg_alpha': 0.026451805477825743, 'reg_lambda': 0.9127043266783162}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:29,027]\u001b[0m Trial 18 finished with value: 0.7623085362674634 and parameters: {'learning_rate': 0.379317982789415, 'n_estimators': 608, 'max_depth': 11, 'reg_alpha': 0.013858009664748724, 'reg_lambda': 0.10464724583875615}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:30,035]\u001b[0m Trial 19 finished with value: 0.7628624812725768 and parameters: {'learning_rate': 0.0054122857438031, 'n_estimators': 783, 'max_depth': 5, 'reg_alpha': 0.15076055653784773, 'reg_lambda': 0.0038986608754902575}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:30,275]\u001b[0m Trial 20 finished with value: 0.7634719282012793 and parameters: {'learning_rate': 0.14178811557868554, 'n_estimators': 454, 'max_depth': 8, 'reg_alpha': 0.003428607853777026, 'reg_lambda': 0.0010679465071239804}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:30,903]\u001b[0m Trial 21 finished with value: 0.7655032986046458 and parameters: {'learning_rate': 0.02292581294316141, 'n_estimators': 862, 'max_depth': 14, 'reg_alpha': 0.0015556917383770952, 'reg_lambda': 0.06093007191281518}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:31,986]\u001b[0m Trial 22 finished with value: 0.7641182570533993 and parameters: {'learning_rate': 0.011314496808042, 'n_estimators': 938, 'max_depth': 15, 'reg_alpha': 0.0013406059282672768, 'reg_lambda': 0.16364134823830345}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:32,341]\u001b[0m Trial 23 finished with value: 0.7652447670637978 and parameters: {'learning_rate': 0.059359336482528315, 'n_estimators': 878, 'max_depth': 12, 'reg_alpha': 0.005726001799199467, 'reg_lambda': 0.25436573290373926}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:32,932]\u001b[0m Trial 24 finished with value: 0.7642475228238234 and parameters: {'learning_rate': 0.0255181832349815, 'n_estimators': 697, 'max_depth': 15, 'reg_alpha': 0.03671359832359421, 'reg_lambda': 0.06311998476693931}. Best is trial 5 with value: 0.7667590743854684.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:33,151]\u001b[0m Trial 25 finished with value: 0.768587415171576 and parameters: {'learning_rate': 0.43672890716507723, 'n_estimators': 987, 'max_depth': 10, 'reg_alpha': 0.0016937572951911438, 'reg_lambda': 0.034104324927647825}. Best is trial 25 with value: 0.768587415171576.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:33,374]\u001b[0m Trial 26 finished with value: 0.762142388573622 and parameters: {'learning_rate': 0.4585381427183964, 'n_estimators': 996, 'max_depth': 10, 'reg_alpha': 0.09228921926795514, 'reg_lambda': 0.019248682471275997}. Best is trial 25 with value: 0.768587415171576.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:33,525]\u001b[0m Trial 27 finished with value: 0.7629917470430008 and parameters: {'learning_rate': 0.1838046848715121, 'n_estimators': 249, 'max_depth': 4, 'reg_alpha': 0.3261742346440614, 'reg_lambda': 0.0076299758910770305}. Best is trial 25 with value: 0.768587415171576.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:33,738]\u001b[0m Trial 28 finished with value: 0.7586335927720023 and parameters: {'learning_rate': 0.46084169013506515, 'n_estimators': 762, 'max_depth': 8, 'reg_alpha': 0.0031748801232254716, 'reg_lambda': 0.005218376154553765}. Best is trial 25 with value: 0.768587415171576.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:33,963]\u001b[0m Trial 29 finished with value: 0.7667776943856403 and parameters: {'learning_rate': 0.5450739617793605, 'n_estimators': 917, 'max_depth': 12, 'reg_alpha': 0.014764206393304025, 'reg_lambda': 0.0332225289386951}. Best is trial 25 with value: 0.768587415171576.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:34,185]\u001b[0m Trial 30 finished with value: 0.7761593098568551 and parameters: {'learning_rate': 0.8936225822808946, 'n_estimators': 800, 'max_depth': 10, 'reg_alpha': 0.0018769920074546804, 'reg_lambda': 0.0378112805859489}. Best is trial 30 with value: 0.7761593098568551.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:34,396]\u001b[0m Trial 31 finished with value: 0.7744233529177541 and parameters: {'learning_rate': 0.8536727657987959, 'n_estimators': 843, 'max_depth': 12, 'reg_alpha': 0.0019319408576657863, 'reg_lambda': 0.033789165418777016}. Best is trial 30 with value: 0.7761593098568551.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:34,618]\u001b[0m Trial 32 finished with value: 0.7757715125455832 and parameters: {'learning_rate': 0.9400537202446515, 'n_estimators': 842, 'max_depth': 10, 'reg_alpha': 0.0021258146228911976, 'reg_lambda': 0.030553104233245504}. Best is trial 30 with value: 0.7761593098568551.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:34,832]\u001b[0m Trial 33 finished with value: 0.7761593098568551 and parameters: {'learning_rate': 0.9960369406166225, 'n_estimators': 834, 'max_depth': 10, 'reg_alpha': 0.0018838925024084118, 'reg_lambda': 0.043949717595390146}. Best is trial 30 with value: 0.7761593098568551.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:35,056]\u001b[0m Trial 34 finished with value: 0.7761593098568551 and parameters: {'learning_rate': 0.9735541191358654, 'n_estimators': 821, 'max_depth': 10, 'reg_alpha': 0.0024267295785472065, 'reg_lambda': 0.09116962965290797}. Best is trial 30 with value: 0.7761593098568551.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:35,280]\u001b[0m Trial 35 finished with value: 0.7751989475402981 and parameters: {'learning_rate': 0.9818292506301645, 'n_estimators': 805, 'max_depth': 9, 'reg_alpha': 0.0026049254007015268, 'reg_lambda': 0.07326588036664441}. Best is trial 30 with value: 0.7761593098568551.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:35,499]\u001b[0m Trial 36 finished with value: 0.7689014486360133 and parameters: {'learning_rate': 0.5945620045189782, 'n_estimators': 726, 'max_depth': 10, 'reg_alpha': 0.004809839144374849, 'reg_lambda': 0.01905065763194133}. Best is trial 30 with value: 0.7761593098568551.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:35,714]\u001b[0m Trial 37 finished with value: 0.7762516937038618 and parameters: {'learning_rate': 0.988106545136767, 'n_estimators': 809, 'max_depth': 8, 'reg_alpha': 0.0010213691245675122, 'reg_lambda': 0.04676899086488728}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:37,397]\u001b[0m Trial 38 finished with value: 0.7492705973009592 and parameters: {'learning_rate': 0.0010408640045333451, 'n_estimators': 800, 'max_depth': 8, 'reg_alpha': 0.0010815859137683038, 'reg_lambda': 0.08027126378156905}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:37,601]\u001b[0m Trial 39 finished with value: 0.7653926528343938 and parameters: {'learning_rate': 0.5740348151068159, 'n_estimators': 650, 'max_depth': 7, 'reg_alpha': 0.0025927877642898237, 'reg_lambda': 0.049727665159595966}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:37,841]\u001b[0m Trial 40 finished with value: 0.7587997404658439 and parameters: {'learning_rate': 0.2444925687848684, 'n_estimators': 590, 'max_depth': 9, 'reg_alpha': 0.009521157057439203, 'reg_lambda': 0.01209372403832982}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:38,067]\u001b[0m Trial 41 finished with value: 0.7492523353777139 and parameters: {'learning_rate': 0.7220497934967618, 'n_estimators': 913, 'max_depth': 10, 'reg_alpha': 0.0019722151228009034, 'reg_lambda': 0.02480282803217842}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:38,311]\u001b[0m Trial 42 finished with value: 0.7744602348411713 and parameters: {'learning_rate': 0.9234692876210677, 'n_estimators': 824, 'max_depth': 11, 'reg_alpha': 0.0010970291154038117, 'reg_lambda': 0.23310747326225983}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:38,519]\u001b[0m Trial 43 finished with value: 0.7751989475402981 and parameters: {'learning_rate': 0.9633619208185653, 'n_estimators': 697, 'max_depth': 9, 'reg_alpha': 0.004686099163346874, 'reg_lambda': 0.044341726199071424}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:38,751]\u001b[0m Trial 44 finished with value: 0.7711544686568105 and parameters: {'learning_rate': 0.6352624871971305, 'n_estimators': 746, 'max_depth': 8, 'reg_alpha': 0.002378423451242579, 'reg_lambda': 0.0989750919048605}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:38,975]\u001b[0m Trial 45 finished with value: 0.7654664166812284 and parameters: {'learning_rate': 0.37540984569212305, 'n_estimators': 891, 'max_depth': 10, 'reg_alpha': 0.0014177916330248316, 'reg_lambda': 0.02401157435553895}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:39,204]\u001b[0m Trial 46 finished with value: 0.7443216161014302 and parameters: {'learning_rate': 0.6498665025165127, 'n_estimators': 820, 'max_depth': 13, 'reg_alpha': 0.006514845436854788, 'reg_lambda': 0.012963299960935554}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:40,540]\u001b[0m Trial 47 finished with value: 0.7599631323996597 and parameters: {'learning_rate': 0.0026292200088863125, 'n_estimators': 672, 'max_depth': 6, 'reg_alpha': 0.0010157685642736573, 'reg_lambda': 0.05394467832834926}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:40,772]\u001b[0m Trial 48 finished with value: 0.7648200878291085 and parameters: {'learning_rate': 0.3211219227019787, 'n_estimators': 501, 'max_depth': 11, 'reg_alpha': 0.0040252596840202265, 'reg_lambda': 0.042355693996448056}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:41,006]\u001b[0m Trial 49 finished with value: 0.767627052855019 and parameters: {'learning_rate': 0.20056677346523974, 'n_estimators': 779, 'max_depth': 9, 'reg_alpha': 0.0027292313066550446, 'reg_lambda': 0.1794551096680158}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:41,284]\u001b[0m Trial 50 finished with value: 0.7655032986046458 and parameters: {'learning_rate': 0.12052276830423558, 'n_estimators': 838, 'max_depth': 12, 'reg_alpha': 0.0019905451534884414, 'reg_lambda': 0.09424468893228508}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:41,511]\u001b[0m Trial 51 finished with value: 0.7751989475402981 and parameters: {'learning_rate': 0.9440930578812082, 'n_estimators': 949, 'max_depth': 9, 'reg_alpha': 0.0026403338126116706, 'reg_lambda': 0.07051588342785507}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:41,731]\u001b[0m Trial 52 finished with value: 0.7646170582118498 and parameters: {'learning_rate': 0.7121538939310768, 'n_estimators': 949, 'max_depth': 8, 'reg_alpha': 0.0014363454865293467, 'reg_lambda': 0.4465790635803166}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:41,970]\u001b[0m Trial 53 finished with value: 0.7751989475402981 and parameters: {'learning_rate': 0.9922441277674868, 'n_estimators': 733, 'max_depth': 9, 'reg_alpha': 0.002184921959674909, 'reg_lambda': 0.1284651938093956}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:42,193]\u001b[0m Trial 54 finished with value: 0.7699724567228227 and parameters: {'learning_rate': 0.4399193809116933, 'n_estimators': 788, 'max_depth': 10, 'reg_alpha': 0.0030791158556346693, 'reg_lambda': 0.0795227011705843}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:42,425]\u001b[0m Trial 55 finished with value: 0.7688645667125961 and parameters: {'learning_rate': 0.7538338518024565, 'n_estimators': 902, 'max_depth': 11, 'reg_alpha': 0.0013829063756871172, 'reg_lambda': 0.041991148235959154}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:42,629]\u001b[0m Trial 56 finished with value: 0.7657804501456658 and parameters: {'learning_rate': 0.5333168452730068, 'n_estimators': 722, 'max_depth': 7, 'reg_alpha': 0.008977977568941019, 'reg_lambda': 0.025407059569303767}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:42,831]\u001b[0m Trial 57 finished with value: 0.7686242970949936 and parameters: {'learning_rate': 0.3504932267555702, 'n_estimators': 861, 'max_depth': 6, 'reg_alpha': 0.0019042412683087154, 'reg_lambda': 0.14961913276548885}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:43,057]\u001b[0m Trial 58 finished with value: 0.7751989475402981 and parameters: {'learning_rate': 0.9840536869012488, 'n_estimators': 743, 'max_depth': 9, 'reg_alpha': 0.004524659555903883, 'reg_lambda': 0.10939931690798657}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:43,283]\u001b[0m Trial 59 finished with value: 0.7603140477875142 and parameters: {'learning_rate': 0.25198222516419505, 'n_estimators': 814, 'max_depth': 11, 'reg_alpha': 0.0035175164892511895, 'reg_lambda': 0.054333464966798}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:43,510]\u001b[0m Trial 60 finished with value: 0.7686615370953372 and parameters: {'learning_rate': 0.7468287991319879, 'n_estimators': 689, 'max_depth': 10, 'reg_alpha': 0.0050090460312202075, 'reg_lambda': 0.04304422883038903}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:43,726]\u001b[0m Trial 61 finished with value: 0.7724840082844678 and parameters: {'learning_rate': 0.5437053199471333, 'n_estimators': 621, 'max_depth': 9, 'reg_alpha': 0.982146730874963, 'reg_lambda': 0.12561473908002682}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:43,953]\u001b[0m Trial 62 finished with value: 0.7728535436724941 and parameters: {'learning_rate': 0.7679178130762163, 'n_estimators': 739, 'max_depth': 8, 'reg_alpha': 0.0022288342086638157, 'reg_lambda': 0.11672528866436946}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:44,173]\u001b[0m Trial 63 finished with value: 0.7697139251819747 and parameters: {'learning_rate': 0.4513679606791289, 'n_estimators': 769, 'max_depth': 9, 'reg_alpha': 0.0015759476676881112, 'reg_lambda': 0.09163919628560714}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:44,405]\u001b[0m Trial 64 finished with value: 0.7744602348411713 and parameters: {'learning_rate': 0.9648303511333421, 'n_estimators': 567, 'max_depth': 10, 'reg_alpha': 0.0012399607572857092, 'reg_lambda': 0.22337806333268526}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:44,621]\u001b[0m Trial 65 finished with value: 0.7703233721106773 and parameters: {'learning_rate': 0.6275371724251797, 'n_estimators': 848, 'max_depth': 8, 'reg_alpha': 0.003950133157053318, 'reg_lambda': 0.3587669396027277}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:44,850]\u001b[0m Trial 66 finished with value: 0.7728535436724941 and parameters: {'learning_rate': 0.7936165051168055, 'n_estimators': 885, 'max_depth': 10, 'reg_alpha': 0.0017586662583045462, 'reg_lambda': 0.17925121422729337}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:45,060]\u001b[0m Trial 67 finished with value: 0.7606649631753689 and parameters: {'learning_rate': 0.4854436150865084, 'n_estimators': 759, 'max_depth': 7, 'reg_alpha': 0.0022132527266903, 'reg_lambda': 0.029997653861510112}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:45,282]\u001b[0m Trial 68 finished with value: 0.7648200878291085 and parameters: {'learning_rate': 0.3910793958869836, 'n_estimators': 802, 'max_depth': 11, 'reg_alpha': 0.005600092785676926, 'reg_lambda': 0.014923283560177565}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:45,651]\u001b[0m Trial 69 finished with value: 0.7637304597421273 and parameters: {'learning_rate': 0.040722611989132705, 'n_estimators': 972, 'max_depth': 8, 'reg_alpha': 0.0031997498817383503, 'reg_lambda': 0.0746805609264441}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:45,887]\u001b[0m Trial 70 finished with value: 0.7614405577979129 and parameters: {'learning_rate': 0.2975849757649086, 'n_estimators': 930, 'max_depth': 12, 'reg_alpha': 0.0028136906270424425, 'reg_lambda': 0.06492401198090068}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:46,102]\u001b[0m Trial 71 finished with value: 0.7751989475402981 and parameters: {'learning_rate': 0.9894080235315068, 'n_estimators': 695, 'max_depth': 9, 'reg_alpha': 0.0012186033494683117, 'reg_lambda': 0.03683177804534632}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:46,328]\u001b[0m Trial 72 finished with value: 0.7751989475402981 and parameters: {'learning_rate': 0.9743624283399868, 'n_estimators': 828, 'max_depth': 9, 'reg_alpha': 0.0016563931776305467, 'reg_lambda': 0.13020171338526124}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:46,553]\u001b[0m Trial 73 finished with value: 0.7747187663820193 and parameters: {'learning_rate': 0.7823427131891524, 'n_estimators': 703, 'max_depth': 10, 'reg_alpha': 0.0012576725322268173, 'reg_lambda': 0.04023783640810792}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:46,774]\u001b[0m Trial 74 finished with value: 0.763176514737014 and parameters: {'learning_rate': 0.5884924481797293, 'n_estimators': 825, 'max_depth': 9, 'reg_alpha': 0.0016738109680727756, 'reg_lambda': 0.0533587985692212}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:47,006]\u001b[0m Trial 75 finished with value: 0.7599448704764142 and parameters: {'learning_rate': 0.6898064288200333, 'n_estimators': 786, 'max_depth': 10, 'reg_alpha': 0.0022656953085010557, 'reg_lambda': 0.02198545059275472}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:47,234]\u001b[0m Trial 76 finished with value: 0.7744233529177541 and parameters: {'learning_rate': 0.851306210927207, 'n_estimators': 875, 'max_depth': 11, 'reg_alpha': 0.00687827643740082, 'reg_lambda': 0.06981594559697864}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:47,452]\u001b[0m Trial 77 finished with value: 0.765041737446539 and parameters: {'learning_rate': 0.5009741931787469, 'n_estimators': 904, 'max_depth': 9, 'reg_alpha': 0.0027638594071760477, 'reg_lambda': 0.030481209845779397}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:47,742]\u001b[0m Trial 78 finished with value: 0.7657618301454938 and parameters: {'learning_rate': 0.07521827026700481, 'n_estimators': 858, 'max_depth': 7, 'reg_alpha': 0.004256693815994801, 'reg_lambda': 0.06362442456021956}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:48,585]\u001b[0m Trial 79 finished with value: 0.7651155012933739 and parameters: {'learning_rate': 0.012108961972246236, 'n_estimators': 838, 'max_depth': 8, 'reg_alpha': 0.0010061404556444744, 'reg_lambda': 0.03828300052634298}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:48,955]\u001b[0m Trial 80 finished with value: 0.7649862355229499 and parameters: {'learning_rate': 0.05146599296190853, 'n_estimators': 959, 'max_depth': 9, 'reg_alpha': 0.0030549817497486894, 'reg_lambda': 0.048588030986569115}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:49,191]\u001b[0m Trial 81 finished with value: 0.7751989475402981 and parameters: {'learning_rate': 0.9598654156819374, 'n_estimators': 811, 'max_depth': 9, 'reg_alpha': 0.0012118899079425715, 'reg_lambda': 0.07982156574116317}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:49,422]\u001b[0m Trial 82 finished with value: 0.7751989475402981 and parameters: {'learning_rate': 0.8454755125162915, 'n_estimators': 725, 'max_depth': 10, 'reg_alpha': 0.004531429681680209, 'reg_lambda': 0.09070908115461056}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:49,654]\u001b[0m Trial 83 finished with value: 0.7637490797422991 and parameters: {'learning_rate': 0.6610916232602082, 'n_estimators': 655, 'max_depth': 10, 'reg_alpha': 0.05988859094668424, 'reg_lambda': 0.08859202844598577}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:49,885]\u001b[0m Trial 84 finished with value: 0.7751989475402981 and parameters: {'learning_rate': 0.8136789008294587, 'n_estimators': 767, 'max_depth': 10, 'reg_alpha': 0.012052410721815484, 'reg_lambda': 0.049029471227177095}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:50,128]\u001b[0m Trial 85 finished with value: 0.7598156047059902 and parameters: {'learning_rate': 0.6082765092180805, 'n_estimators': 795, 'max_depth': 11, 'reg_alpha': 0.014636621544732902, 'reg_lambda': 0.04693443258322043}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:50,357]\u001b[0m Trial 86 finished with value: 0.7751989475402981 and parameters: {'learning_rate': 0.8289780896359217, 'n_estimators': 811, 'max_depth': 10, 'reg_alpha': 0.027414154915113734, 'reg_lambda': 0.059637918397174125}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:51,955]\u001b[0m Trial 87 finished with value: 0.7639889912829753 and parameters: {'learning_rate': 0.005865553936872471, 'n_estimators': 678, 'max_depth': 11, 'reg_alpha': 0.019752736486081796, 'reg_lambda': 0.027879053274520126}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:52,174]\u001b[0m Trial 88 finished with value: 0.7693261278707028 and parameters: {'learning_rate': 0.5240511427905803, 'n_estimators': 624, 'max_depth': 8, 'reg_alpha': 0.001971990510756868, 'reg_lambda': 0.034456549529517974}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:52,396]\u001b[0m Trial 89 finished with value: 0.7645615562882605 and parameters: {'learning_rate': 0.39753148550758777, 'n_estimators': 932, 'max_depth': 9, 'reg_alpha': 0.2718707772189835, 'reg_lambda': 0.009892397382442708}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:52,626]\u001b[0m Trial 90 finished with value: 0.7751989475402981 and parameters: {'learning_rate': 0.9666571056553499, 'n_estimators': 877, 'max_depth': 9, 'reg_alpha': 0.0016038584083839238, 'reg_lambda': 0.151593982994819}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:52,848]\u001b[0m Trial 91 finished with value: 0.7751989475402981 and parameters: {'learning_rate': 0.9940632791992209, 'n_estimators': 886, 'max_depth': 9, 'reg_alpha': 0.0016004923834351463, 'reg_lambda': 0.1421891143882209}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:53,060]\u001b[0m Trial 92 finished with value: 0.7654850366814003 and parameters: {'learning_rate': 0.6747221051991878, 'n_estimators': 870, 'max_depth': 8, 'reg_alpha': 0.0024707590344174362, 'reg_lambda': 0.2871324431627374}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:53,281]\u001b[0m Trial 93 finished with value: 0.7449679449535503 and parameters: {'learning_rate': 0.7034014564406619, 'n_estimators': 739, 'max_depth': 8, 'reg_alpha': 0.0021269684351704803, 'reg_lambda': 0.11051027332199191}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:53,505]\u001b[0m Trial 94 finished with value: 0.775328213310722 and parameters: {'learning_rate': 0.8719246695210501, 'n_estimators': 834, 'max_depth': 9, 'reg_alpha': 0.0012131194602365096, 'reg_lambda': 0.20839399116734356}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:53,723]\u001b[0m Trial 95 finished with value: 0.7642661428239952 and parameters: {'learning_rate': 0.5893625805702687, 'n_estimators': 849, 'max_depth': 9, 'reg_alpha': 0.001397544208218717, 'reg_lambda': 0.20291501036529022}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:53,951]\u001b[0m Trial 96 finished with value: 0.7654850366814003 and parameters: {'learning_rate': 0.8289155423716839, 'n_estimators': 912, 'max_depth': 9, 'reg_alpha': 0.0012506566394360642, 'reg_lambda': 0.45231737388199245}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:54,139]\u001b[0m Trial 97 finished with value: 0.7709883209629691 and parameters: {'learning_rate': 0.9829600271932941, 'n_estimators': 835, 'max_depth': 7, 'reg_alpha': 0.001187515042035658, 'reg_lambda': 0.020256586220142578}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:54,369]\u001b[0m Trial 98 finished with value: 0.7652633870639698 and parameters: {'learning_rate': 0.500133191310595, 'n_estimators': 778, 'max_depth': 10, 'reg_alpha': 0.001802283721898653, 'reg_lambda': 0.12638348419157533}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 13:52:54,577]\u001b[0m Trial 99 finished with value: 0.7705081398046905 and parameters: {'learning_rate': 0.7099387129767778, 'n_estimators': 821, 'max_depth': 8, 'reg_alpha': 0.0010089512473358182, 'reg_lambda': 0.08180975521682185}. Best is trial 37 with value: 0.7762516937038618.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sampler = TPESampler(seed = 39)\n",
    "study = optuna.create_study(\n",
    "    study_name = \"lgb_parameter_opt\",\n",
    "    direction = \"maximize\",\n",
    "    sampler = sampler)\n",
    "study.optimize(objective, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b3c84ef-6a09-4b0c-bf50-e1a4a6484f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score : 0.7762516937038618\n",
      "Best trial : {'learning_rate': 0.988106545136767, 'n_estimators': 809, 'max_depth': 8, 'reg_alpha': 0.0010213691245675122, 'reg_lambda': 0.04676899086488728}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score :\", study.best_value)\n",
    "print(\"Best trial :\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d3c5b74c-c778-402f-9509-4d863fca1fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095, 2)\n",
      "(9866, 2)\n",
      "training model for CV #1\n",
      "training model for CV #2\n",
      "training model for CV #3\n",
      "training model for CV #4\n",
      "training model for CV #5\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증해서 얻은 초모수를 가지고 train 데이터의 예측 불량률을 파악한다.\n",
    "\n",
    "n_fold = 5\n",
    "cv = StratifiedKFold(n_splits = n_fold, shuffle = True, random_state = 39)\n",
    "\n",
    "lgb_val = np.zeros((X_train.shape[0], 2))\n",
    "lgb_partrain = np.zeros((X_partrain.shape[0], 2))\n",
    "\n",
    "print(lgb_val.shape)\n",
    "print(lgb_partrain.shape)\n",
    "\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(X_train, y_train), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    optuna_lgb = lgb.LGBMClassifier(\n",
    "        random_state = 39,\n",
    "        learning_rate = 0.988106545136767, \n",
    "        n_estimators = 809, \n",
    "        max_depth = 8,\n",
    "        reg_alpha = 0.0010213691245675122,\n",
    "        reg_lambda = 0.04676899086488728)\n",
    "\n",
    "    optuna_lgb.fit(X_train.loc[i_trn, :], y_train[i_trn], verbose = False)\n",
    "\n",
    "    lgb_val[i_val, :] = optuna_lgb.predict_proba(X_train.loc[i_val, :])\n",
    "    lgb_partrain += optuna_lgb.predict_proba(X_partrain) / n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7eadeccf-baaa-4fd1-b121-4d74108f989e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095, 2)\n",
      "(14095, 23)\n"
     ]
    }
   ],
   "source": [
    "print(lgb_val.shape)\n",
    "\n",
    "train_teacher['Lgb_prob1'] = lgb_val[:, 1]\n",
    "print(train_teacher.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2f1071-648a-4f27-96bd-118e6551ddd5",
   "metadata": {},
   "source": [
    "# 3. RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "97a0440b-2af1-4e54-8ddf-bf60cc38f8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9866, 20)\n",
      "(4229, 20)\n",
      "(9866,)\n",
      "(4229,)\n"
     ]
    }
   ],
   "source": [
    "train1 = Rdata_train.copy()\n",
    "test1 = Rdata_test.copy()\n",
    "\n",
    "train2 = train1.loc[:, ['COMPONENT_ARBITRARY', 'ANONYMOUS_1', 'YEAR', 'ANONYMOUS_2', 'AG',\n",
    "                                        'CO', 'CR', 'CU', 'FE', 'H2O', 'MN', 'MO', 'NI', 'PQINDEX', 'TI', 'V',\n",
    "                                        'V40', 'ZN', 'Y_LABEL', 'AL', 'BA']]\n",
    "test2 = test1.drop(['ID'], axis = 1)\n",
    "\n",
    "le1 = LabelEncoder()\n",
    "le2 = LabelEncoder()\n",
    "\n",
    "train2['COMPONENT_ARBITRARY_category'] = le1.fit_transform(train2['COMPONENT_ARBITRARY'])\n",
    "train2['YEAR_category'] = le2.fit_transform(train2['YEAR'])\n",
    "\n",
    "test2['COMPONENT_ARBITRARY_category'] = le1.transform(test2['COMPONENT_ARBITRARY'])\n",
    "test2['YEAR_category'] = le2.transform(test2['YEAR'])\n",
    "\n",
    "train3 = train2.drop(['COMPONENT_ARBITRARY', 'YEAR'], axis = 1)\n",
    "test3 = test2.drop(['COMPONENT_ARBITRARY', 'YEAR'], axis = 1)\n",
    "\n",
    "categorical_features = ['COMPONENT_ARBITRARY_category', 'YEAR_category']\n",
    "\n",
    "X_train = train3.drop(['Y_LABEL'], axis = 1)\n",
    "y_train = train3['Y_LABEL']\n",
    "X_test = test3\n",
    "\n",
    "X_partrain, X_val, y_partrain, y_val = train_test_split(X_train, y_train, test_size = 0.3, random_state = 39, stratify = y_train)\n",
    "print(X_partrain.shape)\n",
    "print(X_val.shape)\n",
    "print(y_partrain.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c0ce8014-9a5d-4744-89e2-8ebcf4d94568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial : Trial) -> float :\n",
    "\n",
    "    params_rf = {\n",
    "        \"random_state\" : 39,\n",
    "        \"n_estimators\" : trial.suggest_int(\"n_estimators\", 100, 1000), \n",
    "        \"max_depth\" : trial.suggest_int(\"max_depth\", 3, 16) \n",
    "        }\n",
    "    \n",
    "    model = RandomForestClassifier(**params_rf)\n",
    "    model.fit(X_partrain, y_partrain)\n",
    "\n",
    "    rf_pred = model.predict(X_val)\n",
    "    AUC = roc_auc_score(y_val, rf_pred)\n",
    "    \n",
    "    return AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c5642f1-a932-45f6-b541-8fceb6ac02be",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-10 14:23:52,330]\u001b[0m A new study created in memory with name: rf_parameter_opt\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:24:01,192]\u001b[0m Trial 0 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 592, 'max_depth': 14}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:24:06,222]\u001b[0m Trial 1 finished with value: 0.7477562899792889 and parameters: {'n_estimators': 839, 'max_depth': 4}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:24:13,372]\u001b[0m Trial 2 finished with value: 0.758448825077989 and parameters: {'n_estimators': 642, 'max_depth': 10}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:24:18,662]\u001b[0m Trial 3 finished with value: 0.7570637835267428 and parameters: {'n_estimators': 517, 'max_depth': 9}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:24:27,845]\u001b[0m Trial 4 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 670, 'max_depth': 15}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:24:39,721]\u001b[0m Trial 5 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 834, 'max_depth': 16}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:24:48,437]\u001b[0m Trial 6 finished with value: 0.7570637835267428 and parameters: {'n_estimators': 928, 'max_depth': 8}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:25:00,303]\u001b[0m Trial 7 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 844, 'max_depth': 16}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:25:05,446]\u001b[0m Trial 8 finished with value: 0.7548107635059454 and parameters: {'n_estimators': 665, 'max_depth': 6}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:25:14,197]\u001b[0m Trial 9 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 633, 'max_depth': 15}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:25:17,229]\u001b[0m Trial 10 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 247, 'max_depth': 12}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:25:22,436]\u001b[0m Trial 11 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 407, 'max_depth': 13}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:25:27,926]\u001b[0m Trial 12 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 428, 'max_depth': 13}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:25:31,076]\u001b[0m Trial 13 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 236, 'max_depth': 14}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:25:32,326]\u001b[0m Trial 14 finished with value: 0.7585780908484131 and parameters: {'n_estimators': 106, 'max_depth': 11}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:25:42,116]\u001b[0m Trial 15 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 721, 'max_depth': 14}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:25:47,927]\u001b[0m Trial 16 finished with value: 0.7597046008588118 and parameters: {'n_estimators': 501, 'max_depth': 11}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:25:50,669]\u001b[0m Trial 17 finished with value: 0.7573223150675906 and parameters: {'n_estimators': 289, 'max_depth': 8}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:26:00,154]\u001b[0m Trial 18 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 740, 'max_depth': 13}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:26:13,056]\u001b[0m Trial 19 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 971, 'max_depth': 14}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:26:16,942]\u001b[0m Trial 20 finished with value: 0.7069806380644367 and parameters: {'n_estimators': 755, 'max_depth': 3}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:26:26,126]\u001b[0m Trial 21 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 721, 'max_depth': 13}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:26:33,267]\u001b[0m Trial 22 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 582, 'max_depth': 12}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:26:44,017]\u001b[0m Trial 23 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 813, 'max_depth': 14}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:26:57,882]\u001b[0m Trial 24 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 999, 'max_depth': 15}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:27:04,882]\u001b[0m Trial 25 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 569, 'max_depth': 12}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:27:11,543]\u001b[0m Trial 26 finished with value: 0.7598338666292357 and parameters: {'n_estimators': 572, 'max_depth': 11}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:27:25,000]\u001b[0m Trial 27 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 985, 'max_depth': 15}. Best is trial 0 with value: 0.7612189081804822.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:27:30,383]\u001b[0m Trial 28 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 363, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:27:35,744]\u001b[0m Trial 29 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 382, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:27:40,841]\u001b[0m Trial 30 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 359, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:27:45,868]\u001b[0m Trial 31 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 354, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:27:52,263]\u001b[0m Trial 32 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 451, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:27:58,652]\u001b[0m Trial 33 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 450, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:28:03,574]\u001b[0m Trial 34 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 346, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:28:08,188]\u001b[0m Trial 35 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 335, 'max_depth': 15}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:28:14,741]\u001b[0m Trial 36 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 475, 'max_depth': 15}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:28:21,071]\u001b[0m Trial 37 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 445, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:28:22,627]\u001b[0m Trial 38 finished with value: 0.753296456184275 and parameters: {'n_estimators': 175, 'max_depth': 5}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:28:29,859]\u001b[0m Trial 39 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 509, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:28:37,079]\u001b[0m Trial 40 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 538, 'max_depth': 14}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:28:43,372]\u001b[0m Trial 41 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 443, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:28:48,628]\u001b[0m Trial 42 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 381, 'max_depth': 15}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:28:55,743]\u001b[0m Trial 43 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 502, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:28:59,757]\u001b[0m Trial 44 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 261, 'max_depth': 15}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:29:03,636]\u001b[0m Trial 45 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 280, 'max_depth': 15}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:29:09,435]\u001b[0m Trial 46 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 392, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:29:12,866]\u001b[0m Trial 47 finished with value: 0.755937273516344 and parameters: {'n_estimators': 391, 'max_depth': 7}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:29:15,327]\u001b[0m Trial 48 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 183, 'max_depth': 14}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:29:19,866]\u001b[0m Trial 49 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 307, 'max_depth': 15}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:29:22,527]\u001b[0m Trial 50 finished with value: 0.758448825077989 and parameters: {'n_estimators': 240, 'max_depth': 10}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:29:28,198]\u001b[0m Trial 51 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 399, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:29:34,796]\u001b[0m Trial 52 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 465, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:29:41,271]\u001b[0m Trial 53 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 456, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:29:45,553]\u001b[0m Trial 54 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 319, 'max_depth': 14}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:29:50,921]\u001b[0m Trial 55 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 415, 'max_depth': 13}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:29:58,374]\u001b[0m Trial 56 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 533, 'max_depth': 15}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:30:03,574]\u001b[0m Trial 57 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 351, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:30:06,502]\u001b[0m Trial 58 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 211, 'max_depth': 15}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:30:14,748]\u001b[0m Trial 59 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 611, 'max_depth': 14}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:30:21,564]\u001b[0m Trial 60 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 479, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:30:28,067]\u001b[0m Trial 61 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 457, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:30:35,324]\u001b[0m Trial 62 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 510, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:30:41,079]\u001b[0m Trial 63 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 415, 'max_depth': 15}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:30:45,143]\u001b[0m Trial 64 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 293, 'max_depth': 15}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:30:52,935]\u001b[0m Trial 65 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 552, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:30:57,569]\u001b[0m Trial 66 finished with value: 0.7570637835267428 and parameters: {'n_estimators': 448, 'max_depth': 9}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:31:02,466]\u001b[0m Trial 67 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 364, 'max_depth': 14}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:31:08,542]\u001b[0m Trial 68 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 427, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:31:15,547]\u001b[0m Trial 69 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 491, 'max_depth': 15}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:31:20,276]\u001b[0m Trial 70 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 365, 'max_depth': 13}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:31:25,113]\u001b[0m Trial 71 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 329, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:31:29,538]\u001b[0m Trial 72 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 311, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:31:36,257]\u001b[0m Trial 73 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 473, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:31:42,420]\u001b[0m Trial 74 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 433, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:31:51,104]\u001b[0m Trial 75 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 612, 'max_depth': 15}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:31:53,345]\u001b[0m Trial 76 finished with value: 0.682308421682847 and parameters: {'n_estimators': 433, 'max_depth': 3}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:31:58,326]\u001b[0m Trial 77 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 350, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:32:03,650]\u001b[0m Trial 78 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 395, 'max_depth': 14}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:32:08,935]\u001b[0m Trial 79 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 382, 'max_depth': 15}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:32:16,249]\u001b[0m Trial 80 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 513, 'max_depth': 15}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:32:18,128]\u001b[0m Trial 81 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 131, 'max_depth': 16}. Best is trial 28 with value: 0.7626039497317288.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:32:19,871]\u001b[0m Trial 82 finished with value: 0.7639889912829753 and parameters: {'n_estimators': 121, 'max_depth': 16}. Best is trial 82 with value: 0.7639889912829753.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:32:21,915]\u001b[0m Trial 83 finished with value: 0.7639889912829753 and parameters: {'n_estimators': 123, 'max_depth': 16}. Best is trial 82 with value: 0.7639889912829753.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:32:23,427]\u001b[0m Trial 84 finished with value: 0.7598338666292357 and parameters: {'n_estimators': 108, 'max_depth': 15}. Best is trial 82 with value: 0.7639889912829753.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:32:26,459]\u001b[0m Trial 85 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 198, 'max_depth': 15}. Best is trial 82 with value: 0.7639889912829753.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:32:29,171]\u001b[0m Trial 86 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 189, 'max_depth': 15}. Best is trial 82 with value: 0.7639889912829753.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:32:31,375]\u001b[0m Trial 87 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 154, 'max_depth': 16}. Best is trial 82 with value: 0.7639889912829753.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:32:33,563]\u001b[0m Trial 88 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 153, 'max_depth': 16}. Best is trial 82 with value: 0.7639889912829753.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:32:35,551]\u001b[0m Trial 89 finished with value: 0.753296456184275 and parameters: {'n_estimators': 250, 'max_depth': 6}. Best is trial 82 with value: 0.7639889912829753.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:32:38,432]\u001b[0m Trial 90 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 214, 'max_depth': 14}. Best is trial 82 with value: 0.7639889912829753.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:32:41,465]\u001b[0m Trial 91 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 226, 'max_depth': 14}. Best is trial 82 with value: 0.7639889912829753.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:32:43,675]\u001b[0m Trial 92 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 159, 'max_depth': 15}. Best is trial 82 with value: 0.7639889912829753.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:32:47,537]\u001b[0m Trial 93 finished with value: 0.7612189081804822 and parameters: {'n_estimators': 271, 'max_depth': 16}. Best is trial 82 with value: 0.7639889912829753.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:32:54,315]\u001b[0m Trial 94 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 477, 'max_depth': 16}. Best is trial 82 with value: 0.7639889912829753.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:33:02,171]\u001b[0m Trial 95 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 554, 'max_depth': 16}. Best is trial 82 with value: 0.7639889912829753.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:33:11,360]\u001b[0m Trial 96 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 648, 'max_depth': 16}. Best is trial 82 with value: 0.7639889912829753.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:33:13,282]\u001b[0m Trial 97 finished with value: 0.7639889912829753 and parameters: {'n_estimators': 122, 'max_depth': 16}. Best is trial 82 with value: 0.7639889912829753.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:33:15,149]\u001b[0m Trial 98 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 130, 'max_depth': 16}. Best is trial 82 with value: 0.7639889912829753.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 14:33:16,954]\u001b[0m Trial 99 finished with value: 0.7626039497317288 and parameters: {'n_estimators': 126, 'max_depth': 16}. Best is trial 82 with value: 0.7639889912829753.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sampler = TPESampler(seed = 39)\n",
    "study = optuna.create_study(\n",
    "    study_name = \"rf_parameter_opt\",\n",
    "    direction = \"maximize\",\n",
    "    sampler = sampler)\n",
    "study.optimize(objective, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ad68ba-512c-4ca1-9df1-251d769fc9e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score : 0.7639889912829753\n",
      "Best trial : {'n_estimators': 121, 'max_depth': 16}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score :\", study.best_value)\n",
    "print(\"Best trial :\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3189684e-f2f7-4ef0-845c-e343ca46dc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095, 2)\n",
      "(9866, 2)\n",
      "training model for CV #1\n",
      "training model for CV #2\n",
      "training model for CV #3\n",
      "training model for CV #4\n",
      "training model for CV #5\n"
     ]
    }
   ],
   "source": [
    "n_fold = 5\n",
    "cv = StratifiedKFold(n_splits = n_fold, shuffle = True, random_state = 39)\n",
    "\n",
    "rf_val = np.zeros((X_train.shape[0], 2))\n",
    "rf_partrain = np.zeros((X_partrain.shape[0], 2))\n",
    "\n",
    "print(rf_val.shape)\n",
    "print(rf_partrain.shape)\n",
    "\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(X_train, y_train), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    optuna_rf = RandomForestClassifier(\n",
    "        random_state = 39,\n",
    "        n_estimators = 121, \n",
    "        max_depth = 16)\n",
    "\n",
    "    optuna_rf.fit(X_train.loc[i_trn, :], y_train[i_trn])\n",
    "\n",
    "    rf_val[i_val, :] = optuna_rf.predict_proba(X_train.loc[i_val, :])\n",
    "    rf_partrain += optuna_rf.predict_proba(X_partrain) / n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "30063c4c-ad99-4d18-a77a-6dd7b016f6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095, 2)\n",
      "(14095, 24)\n"
     ]
    }
   ],
   "source": [
    "print(rf_val.shape)\n",
    "\n",
    "train_teacher['Rf_prob1'] = rf_val[:, 1]\n",
    "print(train_teacher.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2098be0-bf76-4b40-bbf1-2c94433c2115",
   "metadata": {},
   "source": [
    "# 4. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0183a051-8e68-41e1-9b34-ae2567515536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9866, 20)\n",
      "(4229, 20)\n",
      "(9866,)\n",
      "(4229,)\n"
     ]
    }
   ],
   "source": [
    "train1 = Rdata_train.copy()\n",
    "test1 = Rdata_test.copy()\n",
    "\n",
    "train2 = train1.loc[:, ['COMPONENT_ARBITRARY', 'ANONYMOUS_1', 'YEAR', 'ANONYMOUS_2', 'AG',\n",
    "                                        'CO', 'CR', 'CU', 'FE', 'H2O', 'MN', 'MO', 'NI', 'PQINDEX', 'TI', 'V',\n",
    "                                        'V40', 'ZN', 'Y_LABEL', 'AL', 'BA']]\n",
    "test2 = test1.drop(['ID'], axis = 1)\n",
    "\n",
    "le1 = LabelEncoder()\n",
    "le2 = LabelEncoder()\n",
    "\n",
    "train2['COMPONENT_ARBITRARY_category'] = le1.fit_transform(train2['COMPONENT_ARBITRARY'])\n",
    "train2['YEAR_category'] = le2.fit_transform(train2['YEAR'])\n",
    "\n",
    "test2['COMPONENT_ARBITRARY_category'] = le1.transform(test2['COMPONENT_ARBITRARY'])\n",
    "test2['YEAR_category'] = le2.transform(test2['YEAR'])\n",
    "\n",
    "train3 = train2.drop(['COMPONENT_ARBITRARY', 'YEAR'], axis = 1)\n",
    "test3 = test2.drop(['COMPONENT_ARBITRARY', 'YEAR'], axis = 1)\n",
    "\n",
    "categorical_features = ['COMPONENT_ARBITRARY_category', 'YEAR_category']\n",
    "\n",
    "X_train = train3.drop(['Y_LABEL'], axis = 1)\n",
    "y_train = train3['Y_LABEL']\n",
    "X_test = test3\n",
    "\n",
    "X_partrain, X_val, y_partrain, y_val = train_test_split(X_train, y_train, test_size = 0.3, random_state = 39, stratify = y_train)\n",
    "print(X_partrain.shape)\n",
    "print(X_val.shape)\n",
    "print(y_partrain.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6cf97c37-604d-498e-b940-37e009365626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial : Trial) -> float :\n",
    "\n",
    "    params_gbm = {\n",
    "        \"random_state\" : 39,\n",
    "        \"n_estimators\" : trial.suggest_int(\"n_estimators\", 100, 1000), \n",
    "        \"max_depth\" : trial.suggest_int(\"max_depth\", 3, 16),\n",
    "    }\n",
    "    \n",
    "    model = GradientBoostingClassifier(**params_gbm)\n",
    "    model.fit(X_partrain, y_partrain)\n",
    "\n",
    "    gbm_pred = model.predict(X_val)\n",
    "    AUC = roc_auc_score(y_val, gbm_pred)\n",
    "    \n",
    "    return AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "655df5f1-0f20-4fff-8bb4-92e4a5a4c525",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-10 15:51:47,016]\u001b[0m A new study created in memory with name: gbm_parameter_opt\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 15:52:57,465]\u001b[0m Trial 0 finished with value: 0.7628255993491594 and parameters: {'n_estimators': 592, 'max_depth': 14}. Best is trial 0 with value: 0.7628255993491594.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 15:53:17,946]\u001b[0m Trial 1 finished with value: 0.7679410863194561 and parameters: {'n_estimators': 839, 'max_depth': 4}. Best is trial 1 with value: 0.7679410863194561.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 15:54:01,897]\u001b[0m Trial 2 finished with value: 0.7661127455333484 and parameters: {'n_estimators': 642, 'max_depth': 10}. Best is trial 1 with value: 0.7679410863194561.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 15:54:32,567]\u001b[0m Trial 3 finished with value: 0.7619576208796088 and parameters: {'n_estimators': 517, 'max_depth': 9}. Best is trial 1 with value: 0.7679410863194561.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 15:56:00,730]\u001b[0m Trial 4 finished with value: 0.7608311108692102 and parameters: {'n_estimators': 670, 'max_depth': 15}. Best is trial 1 with value: 0.7679410863194561.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 15:57:58,723]\u001b[0m Trial 5 finished with value: 0.756325070827616 and parameters: {'n_estimators': 834, 'max_depth': 16}. Best is trial 1 with value: 0.7679410863194561.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 15:58:46,057]\u001b[0m Trial 6 finished with value: 0.770397135957512 and parameters: {'n_estimators': 928, 'max_depth': 8}. Best is trial 6 with value: 0.770397135957512.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:00:45,243]\u001b[0m Trial 7 finished with value: 0.7549400292763695 and parameters: {'n_estimators': 844, 'max_depth': 16}. Best is trial 6 with value: 0.770397135957512.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:01:09,767]\u001b[0m Trial 8 finished with value: 0.7603140477875142 and parameters: {'n_estimators': 665, 'max_depth': 6}. Best is trial 6 with value: 0.770397135957512.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:02:33,652]\u001b[0m Trial 9 finished with value: 0.7619576208796088 and parameters: {'n_estimators': 633, 'max_depth': 15}. Best is trial 6 with value: 0.770397135957512.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:02:50,536]\u001b[0m Trial 10 finished with value: 0.7594460693179638 and parameters: {'n_estimators': 247, 'max_depth': 10}. Best is trial 6 with value: 0.770397135957512.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:03:08,907]\u001b[0m Trial 11 finished with value: 0.765558800528235 and parameters: {'n_estimators': 990, 'max_depth': 3}. Best is trial 6 with value: 0.770397135957512.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:03:32,700]\u001b[0m Trial 12 finished with value: 0.7680703520898801 and parameters: {'n_estimators': 972, 'max_depth': 4}. Best is trial 6 with value: 0.770397135957512.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:04:15,644]\u001b[0m Trial 13 finished with value: 0.7712651144270627 and parameters: {'n_estimators': 983, 'max_depth': 7}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:04:35,021]\u001b[0m Trial 14 finished with value: 0.7645984382116778 and parameters: {'n_estimators': 444, 'max_depth': 7}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:04:48,193]\u001b[0m Trial 15 finished with value: 0.7590582720066918 and parameters: {'n_estimators': 148, 'max_depth': 12}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:05:27,599]\u001b[0m Trial 16 finished with value: 0.7698800728758161 and parameters: {'n_estimators': 897, 'max_depth': 7}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:06:06,672]\u001b[0m Trial 17 finished with value: 0.770397135957512 and parameters: {'n_estimators': 762, 'max_depth': 8}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:07:15,437]\u001b[0m Trial 18 finished with value: 0.7645984382116778 and parameters: {'n_estimators': 759, 'max_depth': 12}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:07:26,714]\u001b[0m Trial 19 finished with value: 0.7663343951507791 and parameters: {'n_estimators': 369, 'max_depth': 5}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:08:34,218]\u001b[0m Trial 20 finished with value: 0.7645984382116778 and parameters: {'n_estimators': 748, 'max_depth': 12}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:09:21,021]\u001b[0m Trial 21 finished with value: 0.770267870187088 and parameters: {'n_estimators': 918, 'max_depth': 8}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:09:59,819]\u001b[0m Trial 22 finished with value: 0.770397135957512 and parameters: {'n_estimators': 762, 'max_depth': 8}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:10:27,536]\u001b[0m Trial 23 finished with value: 0.7601847820170902 and parameters: {'n_estimators': 751, 'max_depth': 6}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:11:27,143]\u001b[0m Trial 24 finished with value: 0.7684950313245695 and parameters: {'n_estimators': 1000, 'max_depth': 9}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:12:29,268]\u001b[0m Trial 25 finished with value: 0.7687535628654176 and parameters: {'n_estimators': 782, 'max_depth': 11}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:13:05,618]\u001b[0m Trial 26 finished with value: 0.770267870187088 and parameters: {'n_estimators': 714, 'max_depth': 8}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:13:22,966]\u001b[0m Trial 27 finished with value: 0.7587997404658439 and parameters: {'n_estimators': 471, 'max_depth': 6}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:14:02,682]\u001b[0m Trial 28 finished with value: 0.7712651144270627 and parameters: {'n_estimators': 910, 'max_depth': 7}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:14:29,673]\u001b[0m Trial 29 finished with value: 0.7658542139925004 and parameters: {'n_estimators': 885, 'max_depth': 5}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:15:05,691]\u001b[0m Trial 30 finished with value: 0.7673685213141709 and parameters: {'n_estimators': 823, 'max_depth': 7}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:15:54,200]\u001b[0m Trial 31 finished with value: 0.7688828286358416 and parameters: {'n_estimators': 951, 'max_depth': 8}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:16:48,153]\u001b[0m Trial 32 finished with value: 0.767239255543747 and parameters: {'n_estimators': 906, 'max_depth': 9}. Best is trial 13 with value: 0.7712651144270627.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:17:29,097]\u001b[0m Trial 33 finished with value: 0.7713943801974866 and parameters: {'n_estimators': 937, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:17:55,549]\u001b[0m Trial 34 finished with value: 0.7657249482220764 and parameters: {'n_estimators': 867, 'max_depth': 5}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:18:31,455]\u001b[0m Trial 35 finished with value: 0.767239255543747 and parameters: {'n_estimators': 821, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:19:36,585]\u001b[0m Trial 36 finished with value: 0.7658542139925004 and parameters: {'n_estimators': 946, 'max_depth': 10}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:19:58,479]\u001b[0m Trial 37 finished with value: 0.7604433135579381 and parameters: {'n_estimators': 595, 'max_depth': 6}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:20:15,648]\u001b[0m Trial 38 finished with value: 0.7668145763090577 and parameters: {'n_estimators': 702, 'max_depth': 4}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:21:04,010]\u001b[0m Trial 39 finished with value: 0.7659834797629245 and parameters: {'n_estimators': 811, 'max_depth': 9}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:21:41,830]\u001b[0m Trial 40 finished with value: 0.767109989773323 and parameters: {'n_estimators': 866, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:22:29,700]\u001b[0m Trial 41 finished with value: 0.770267870187088 and parameters: {'n_estimators': 938, 'max_depth': 8}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:23:06,924]\u001b[0m Trial 42 finished with value: 0.7633426624308554 and parameters: {'n_estimators': 543, 'max_depth': 10}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:23:54,193]\u001b[0m Trial 43 finished with value: 0.7658542139925004 and parameters: {'n_estimators': 794, 'max_depth': 9}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:24:45,435]\u001b[0m Trial 44 finished with value: 0.770397135957512 and parameters: {'n_estimators': 999, 'max_depth': 8}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:25:08,988]\u001b[0m Trial 45 finished with value: 0.7601847820170902 and parameters: {'n_estimators': 639, 'max_depth': 6}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:26:27,761]\u001b[0m Trial 46 finished with value: 0.767239255543747 and parameters: {'n_estimators': 993, 'max_depth': 11}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:27:09,592]\u001b[0m Trial 47 finished with value: 0.7712651144270627 and parameters: {'n_estimators': 956, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:27:47,052]\u001b[0m Trial 48 finished with value: 0.767109989773323 and parameters: {'n_estimators': 856, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:28:16,114]\u001b[0m Trial 49 finished with value: 0.7643399066708298 and parameters: {'n_estimators': 951, 'max_depth': 5}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:28:33,260]\u001b[0m Trial 50 finished with value: 0.765688066298659 and parameters: {'n_estimators': 910, 'max_depth': 3}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:29:16,036]\u001b[0m Trial 51 finished with value: 0.7712651144270627 and parameters: {'n_estimators': 978, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:29:52,306]\u001b[0m Trial 52 finished with value: 0.7607018450987862 and parameters: {'n_estimators': 970, 'max_depth': 6}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:30:31,313]\u001b[0m Trial 53 finished with value: 0.7684950313245695 and parameters: {'n_estimators': 891, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:31:15,204]\u001b[0m Trial 54 finished with value: 0.7712651144270627 and parameters: {'n_estimators': 999, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:31:50,857]\u001b[0m Trial 55 finished with value: 0.7604433135579381 and parameters: {'n_estimators': 966, 'max_depth': 6}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:32:19,268]\u001b[0m Trial 56 finished with value: 0.7658542139925004 and parameters: {'n_estimators': 928, 'max_depth': 5}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:32:56,459]\u001b[0m Trial 57 finished with value: 0.767109989773323 and parameters: {'n_estimators': 851, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:34:44,990]\u001b[0m Trial 58 finished with value: 0.7588366223892611 and parameters: {'n_estimators': 967, 'max_depth': 14}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:35:32,030]\u001b[0m Trial 59 finished with value: 0.770397135957512 and parameters: {'n_estimators': 920, 'max_depth': 8}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:35:41,040]\u001b[0m Trial 60 finished with value: 0.7603140477875142 and parameters: {'n_estimators': 244, 'max_depth': 6}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:36:28,393]\u001b[0m Trial 61 finished with value: 0.770397135957512 and parameters: {'n_estimators': 928, 'max_depth': 8}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:37:07,374]\u001b[0m Trial 62 finished with value: 0.7684950313245695 and parameters: {'n_estimators': 890, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:37:51,096]\u001b[0m Trial 63 finished with value: 0.7712651144270627 and parameters: {'n_estimators': 999, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:38:14,950]\u001b[0m Trial 64 finished with value: 0.7680703520898801 and parameters: {'n_estimators': 977, 'max_depth': 4}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:39:13,752]\u001b[0m Trial 65 finished with value: 0.7684950313245695 and parameters: {'n_estimators': 987, 'max_depth': 9}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:39:55,779]\u001b[0m Trial 66 finished with value: 0.7712651144270627 and parameters: {'n_estimators': 961, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:40:32,667]\u001b[0m Trial 67 finished with value: 0.7604433135579381 and parameters: {'n_estimators': 999, 'max_depth': 6}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:41:11,397]\u001b[0m Trial 68 finished with value: 0.767109989773323 and parameters: {'n_estimators': 872, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:41:40,224]\u001b[0m Trial 69 finished with value: 0.7643399066708298 and parameters: {'n_estimators': 945, 'max_depth': 5}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:41:59,472]\u001b[0m Trial 70 finished with value: 0.7662420113037723 and parameters: {'n_estimators': 378, 'max_depth': 8}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:42:41,791]\u001b[0m Trial 71 finished with value: 0.7712651144270627 and parameters: {'n_estimators': 965, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:43:21,435]\u001b[0m Trial 72 finished with value: 0.7712651144270627 and parameters: {'n_estimators': 907, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:44:00,593]\u001b[0m Trial 73 finished with value: 0.7698800728758161 and parameters: {'n_estimators': 897, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:44:31,599]\u001b[0m Trial 74 finished with value: 0.7604433135579381 and parameters: {'n_estimators': 841, 'max_depth': 6}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:45:20,061]\u001b[0m Trial 75 finished with value: 0.7688828286358416 and parameters: {'n_estimators': 949, 'max_depth': 8}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:46:17,533]\u001b[0m Trial 76 finished with value: 0.7684950313245695 and parameters: {'n_estimators': 965, 'max_depth': 9}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:46:57,673]\u001b[0m Trial 77 finished with value: 0.7712651144270627 and parameters: {'n_estimators': 917, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:47:31,908]\u001b[0m Trial 78 finished with value: 0.7603140477875142 and parameters: {'n_estimators': 928, 'max_depth': 6}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:48:16,658]\u001b[0m Trial 79 finished with value: 0.7691413601766895 and parameters: {'n_estimators': 878, 'max_depth': 8}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:48:36,095]\u001b[0m Trial 80 finished with value: 0.7680703520898801 and parameters: {'n_estimators': 797, 'max_depth': 4}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:49:15,576]\u001b[0m Trial 81 finished with value: 0.7712651144270627 and parameters: {'n_estimators': 903, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:49:55,189]\u001b[0m Trial 82 finished with value: 0.7712651144270627 and parameters: {'n_estimators': 908, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:50:31,504]\u001b[0m Trial 83 finished with value: 0.7604433135579381 and parameters: {'n_estimators': 984, 'max_depth': 6}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:51:08,403]\u001b[0m Trial 84 finished with value: 0.767109989773323 and parameters: {'n_estimators': 845, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:51:48,201]\u001b[0m Trial 85 finished with value: 0.7712651144270627 and parameters: {'n_estimators': 910, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:52:17,477]\u001b[0m Trial 86 finished with value: 0.7643399066708298 and parameters: {'n_estimators': 955, 'max_depth': 5}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:52:59,503]\u001b[0m Trial 87 finished with value: 0.770267870187088 and parameters: {'n_estimators': 824, 'max_depth': 8}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:53:33,246]\u001b[0m Trial 88 finished with value: 0.7600555162466662 and parameters: {'n_estimators': 906, 'max_depth': 6}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:54:20,756]\u001b[0m Trial 89 finished with value: 0.770267870187088 and parameters: {'n_estimators': 931, 'max_depth': 8}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:55:13,365]\u001b[0m Trial 90 finished with value: 0.767239255543747 and parameters: {'n_estimators': 881, 'max_depth': 9}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:55:54,274]\u001b[0m Trial 91 finished with value: 0.7713943801974866 and parameters: {'n_estimators': 937, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:56:33,927]\u001b[0m Trial 92 finished with value: 0.7712651144270627 and parameters: {'n_estimators': 903, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:57:08,336]\u001b[0m Trial 93 finished with value: 0.7603140477875142 and parameters: {'n_estimators': 934, 'max_depth': 6}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:57:59,342]\u001b[0m Trial 94 finished with value: 0.770397135957512 and parameters: {'n_estimators': 999, 'max_depth': 8}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:58:42,000]\u001b[0m Trial 95 finished with value: 0.7712651144270627 and parameters: {'n_estimators': 977, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 16:59:21,322]\u001b[0m Trial 96 finished with value: 0.7698800728758161 and parameters: {'n_estimators': 901, 'max_depth': 7}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 17:00:10,848]\u001b[0m Trial 97 finished with value: 0.770397135957512 and parameters: {'n_estimators': 971, 'max_depth': 8}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 17:00:37,568]\u001b[0m Trial 98 finished with value: 0.7657249482220764 and parameters: {'n_estimators': 862, 'max_depth': 5}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n",
      "\u001b[32m[I 2022-12-10 17:01:12,845]\u001b[0m Trial 99 finished with value: 0.7603140477875142 and parameters: {'n_estimators': 952, 'max_depth': 6}. Best is trial 33 with value: 0.7713943801974866.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sampler = TPESampler(seed = 39)\n",
    "study = optuna.create_study(\n",
    "    study_name = \"gbm_parameter_opt\",\n",
    "    direction = \"maximize\",\n",
    "    sampler = sampler)\n",
    "study.optimize(objective, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e925b507-5998-4f47-b3eb-3151e331bfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score : 0.7713943801974866\n",
      "Best trial : {'n_estimators': 937, 'max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score :\", study.best_value)\n",
    "print(\"Best trial :\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "28a580bc-ba82-4a90-9941-3cf7022b3b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095, 2)\n",
      "(9866, 2)\n",
      "training model for CV #1\n",
      "training model for CV #2\n",
      "training model for CV #3\n",
      "training model for CV #4\n",
      "training model for CV #5\n"
     ]
    }
   ],
   "source": [
    "n_fold = 5\n",
    "cv = StratifiedKFold(n_splits = n_fold, shuffle = True, random_state = 39)\n",
    "\n",
    "gbm_val = np.zeros((X_train.shape[0], 2))\n",
    "gbm_partrain = np.zeros((X_partrain.shape[0], 2))\n",
    "\n",
    "print(gbm_val.shape)\n",
    "print(gbm_partrain.shape)\n",
    "\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(X_train, y_train), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    optuna_gbm = GradientBoostingClassifier(\n",
    "        random_state = 39,\n",
    "        n_estimators = 937, \n",
    "        max_depth = 7)\n",
    "\n",
    "    optuna_gbm.fit(X_train.loc[i_trn, :], y_train[i_trn])\n",
    "\n",
    "    gbm_val[i_val, :] = optuna_gbm.predict_proba(X_train.loc[i_val, :])\n",
    "    gbm_partrain += optuna_gbm.predict_proba(X_partrain) / n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f5be2456-1fc2-4af5-ae78-66eeecdf2144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095, 2)\n",
      "(14095, 25)\n"
     ]
    }
   ],
   "source": [
    "print(gbm_val.shape)\n",
    "\n",
    "train_teacher['Gbm_prob1'] = gbm_val[:, 1]\n",
    "print(train_teacher.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39886f6-b4c4-4e19-acbe-6bd4588f1494",
   "metadata": {},
   "source": [
    "# 5. HGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "66238843-a748-4e04-a8d1-a9e3ca87a323",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = Rdata_train.copy()\n",
    "test1 = Rdata_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d92e0116-da03-4b93-b332-1a4d8b0519f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095, 21)\n",
      "(6041, 18)\n"
     ]
    }
   ],
   "source": [
    "train2 = train1.loc[:, ['COMPONENT_ARBITRARY', 'ANONYMOUS_1', 'YEAR', 'ANONYMOUS_2', 'AG',\n",
    "                                        'CO', 'CR', 'CU', 'FE', 'H2O', 'MN', 'MO', 'NI', 'PQINDEX', 'TI', 'V',\n",
    "                                        'V40', 'ZN', 'Y_LABEL', 'AL', 'BA']]\n",
    "test2 = test1.drop(['ID'], axis = 1)\n",
    "\n",
    "print(train2.shape) # 변수 20개\n",
    "print(test2.shape) # 변수 18개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a821d44e-992c-4503-9c3f-391fabe06401",
   "metadata": {},
   "outputs": [],
   "source": [
    "le1 = LabelEncoder()\n",
    "le2 = LabelEncoder()\n",
    "\n",
    "train2['COMPONENT_ARBITRARY_category'] = le1.fit_transform(train2['COMPONENT_ARBITRARY'])\n",
    "train2['YEAR_category'] = le2.fit_transform(train2['YEAR'])\n",
    "\n",
    "test2['COMPONENT_ARBITRARY_category'] = le1.transform(test2['COMPONENT_ARBITRARY'])\n",
    "test2['YEAR_category'] = le2.transform(test2['YEAR'])\n",
    "\n",
    "# 원래 범주형 변수는 제거해준다.\n",
    "train3 = train2.drop(['COMPONENT_ARBITRARY', 'YEAR'], axis = 1)\n",
    "test3 = test2.drop(['COMPONENT_ARBITRARY', 'YEAR'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "08b97dce-5d3f-4206-8369-a468a2416784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095, 21)\n",
      "(6041, 18)\n"
     ]
    }
   ],
   "source": [
    "categorical_features = ['COMPONENT_ARBITRARY_category', 'YEAR_category']\n",
    "\n",
    "print(train3.shape)\n",
    "print(test3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7c9c8f3c-6fa1-4499-8232-b75ce256a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train3.drop(['Y_LABEL'], axis = 1)\n",
    "y_train = train3['Y_LABEL']\n",
    "X_test = test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a2979483-a0db-4457-8e8d-44a379cfddaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9866, 20)\n",
      "(4229, 20)\n",
      "(9866,)\n",
      "(4229,)\n"
     ]
    }
   ],
   "source": [
    "X_partrain, X_val, y_partrain, y_val = train_test_split(X_train, y_train, test_size = 0.3, random_state = 39, stratify = y_train)\n",
    "print(X_partrain.shape)\n",
    "print(X_val.shape)\n",
    "print(y_partrain.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2d644b35-4caf-4253-8a81-3d0e017e5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial : Trial) -> float :\n",
    "\n",
    "    params_hgb = {\n",
    "        \"random_state\" : 39,\n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.001, 1), # 학습률이 0.005와 0.5 사이의 랜덤한 값으로 정해줌\n",
    "        \"max_iter\" : trial.suggest_int(\"max_iter\", 100, 1000), # 400과 1000 사이에 랜덤한 값으로 정해줌\n",
    "        \"max_depth\" : trial.suggest_int(\"max_depth\", 3, 16), # 3과 10 사이에 랜덤한 값으로 정해줌\n",
    "        'l2_regularization' : trial.suggest_loguniform('reg_lambda', 0.001, 1)\n",
    "    }\n",
    "    \n",
    "    model = HistGradientBoostingClassifier(**params_hgb) # Catboost가 AutoML에서 가장 좋아서 Catboost로 했다.\n",
    "    model.fit(X_partrain, y_partrain)\n",
    "\n",
    "    hgb_pred = model.predict(X_val)\n",
    "    AUC = roc_auc_score(y_val, hgb_pred)\n",
    "    \n",
    "    return AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08cc7bb5-104a-48ce-83d6-d9209346cf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-11 01:55:37,784]\u001b[0m A new study created in memory with name: hgb_parameter_opt\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:55:42,339]\u001b[0m Trial 0 finished with value: 0.7620868866500329 and parameters: {'learning_rate': 0.04371872304807245, 'max_iter': 818, 'max_depth': 14, 'reg_lambda': 0.002323537042351288}. Best is trial 0 with value: 0.7620868866500329.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:55:45,206]\u001b[0m Trial 1 finished with value: 0.7651155012933739 and parameters: {'learning_rate': 0.0639743703819749, 'max_iter': 573, 'max_depth': 9, 'reg_lambda': 0.02596194546249675}. Best is trial 1 with value: 0.7651155012933739.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:55:50,263]\u001b[0m Trial 2 finished with value: 0.7645984382116778 and parameters: {'learning_rate': 0.07909308741230786, 'max_iter': 934, 'max_depth': 14, 'reg_lambda': 0.6812793998007773}. Best is trial 1 with value: 0.7651155012933739.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:55:52,877]\u001b[0m Trial 3 finished with value: 0.7665560447682097 and parameters: {'learning_rate': 0.5737932383737886, 'max_iter': 473, 'max_depth': 14, 'reg_lambda': 0.68989080483343}. Best is trial 3 with value: 0.7665560447682097.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:55:54,620]\u001b[0m Trial 4 finished with value: 0.7636011939717033 and parameters: {'learning_rate': 0.07658402006781226, 'max_iter': 327, 'max_depth': 11, 'reg_lambda': 0.3812513877805805}. Best is trial 3 with value: 0.7665560447682097.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:55:59,168]\u001b[0m Trial 5 finished with value: 0.755937273516344 and parameters: {'learning_rate': 0.001397517628649231, 'max_iter': 870, 'max_depth': 13, 'reg_lambda': 0.007725388176354637}. Best is trial 3 with value: 0.7665560447682097.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:03,394]\u001b[0m Trial 6 finished with value: 0.7607018450987862 and parameters: {'learning_rate': 0.028590346350381008, 'max_iter': 860, 'max_depth': 11, 'reg_lambda': 0.0029609935336908696}. Best is trial 3 with value: 0.7665560447682097.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:04,848]\u001b[0m Trial 7 finished with value: 0.7610896424100582 and parameters: {'learning_rate': 0.03787099728554101, 'max_iter': 269, 'max_depth': 12, 'reg_lambda': 0.044284069008460006}. Best is trial 3 with value: 0.7665560447682097.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:09,611]\u001b[0m Trial 8 finished with value: 0.7626039497317288 and parameters: {'learning_rate': 0.0029463050635698254, 'max_iter': 940, 'max_depth': 10, 'reg_lambda': 0.09071345093703738}. Best is trial 3 with value: 0.7665560447682097.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:10,775]\u001b[0m Trial 9 finished with value: 0.7633057805074379 and parameters: {'learning_rate': 0.10328626642586429, 'max_iter': 837, 'max_depth': 3, 'reg_lambda': 0.3495701519742112}. Best is trial 3 with value: 0.7665560447682097.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:11,406]\u001b[0m Trial 10 finished with value: 0.7669069601560642 and parameters: {'learning_rate': 0.607433211308066, 'max_iter': 115, 'max_depth': 16, 'reg_lambda': 0.15683405166616982}. Best is trial 10 with value: 0.7669069601560642.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:12,265]\u001b[0m Trial 11 finished with value: 0.7655405386049895 and parameters: {'learning_rate': 0.8112649897234006, 'max_iter': 153, 'max_depth': 16, 'reg_lambda': 0.1542936087087245}. Best is trial 10 with value: 0.7669069601560642.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:15,166]\u001b[0m Trial 12 finished with value: 0.754404704271428 and parameters: {'learning_rate': 0.8196675277364934, 'max_iter': 515, 'max_depth': 16, 'reg_lambda': 0.8907832204193028}. Best is trial 10 with value: 0.7669069601560642.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:17,881]\u001b[0m Trial 13 finished with value: 0.7606649631753689 and parameters: {'learning_rate': 0.29773819361140064, 'max_iter': 570, 'max_depth': 7, 'reg_lambda': 0.17046793973134927}. Best is trial 10 with value: 0.7669069601560642.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:18,453]\u001b[0m Trial 14 finished with value: 0.7613112920274888 and parameters: {'learning_rate': 0.27402715805982697, 'max_iter': 101, 'max_depth': 16, 'reg_lambda': 0.028414885918860346}. Best is trial 10 with value: 0.7669069601560642.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:20,151]\u001b[0m Trial 15 finished with value: 0.7626039497317288 and parameters: {'learning_rate': 0.009265454235359733, 'max_iter': 416, 'max_depth': 7, 'reg_lambda': 0.29544559906711126}. Best is trial 10 with value: 0.7669069601560642.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:24,125]\u001b[0m Trial 16 finished with value: 0.7655956824516524 and parameters: {'learning_rate': 0.2623811642252261, 'max_iter': 679, 'max_depth': 14, 'reg_lambda': 0.07318632675057297}. Best is trial 10 with value: 0.7669069601560642.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:24,876]\u001b[0m Trial 17 finished with value: 0.6825859313007931 and parameters: {'learning_rate': 0.9905987867500259, 'max_iter': 224, 'max_depth': 15, 'reg_lambda': 0.013290538304443295}. Best is trial 10 with value: 0.7669069601560642.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:26,575]\u001b[0m Trial 18 finished with value: 0.7612189081804822 and parameters: {'learning_rate': 0.016315488060593183, 'max_iter': 396, 'max_depth': 8, 'reg_lambda': 0.9157203326006241}. Best is trial 10 with value: 0.7669069601560642.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:27,880]\u001b[0m Trial 19 finished with value: 0.7644322905178366 and parameters: {'learning_rate': 0.1743876762989608, 'max_iter': 671, 'max_depth': 4, 'reg_lambda': 0.18931033979308526}. Best is trial 10 with value: 0.7669069601560642.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:30,101]\u001b[0m Trial 20 finished with value: 0.7658173320690831 and parameters: {'learning_rate': 0.5204772511201463, 'max_iter': 442, 'max_depth': 13, 'reg_lambda': 0.0010941615360892725}. Best is trial 10 with value: 0.7669069601560642.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:32,325]\u001b[0m Trial 21 finished with value: 0.766980724002899 and parameters: {'learning_rate': 0.4694923958584929, 'max_iter': 457, 'max_depth': 13, 'reg_lambda': 0.0011581165869393583}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:36,176]\u001b[0m Trial 22 finished with value: 0.766592926691627 and parameters: {'learning_rate': 0.5109145310991334, 'max_iter': 713, 'max_depth': 15, 'reg_lambda': 0.013296862088410136}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:39,838]\u001b[0m Trial 23 finished with value: 0.7629548651195834 and parameters: {'learning_rate': 0.15554939558367542, 'max_iter': 707, 'max_depth': 15, 'reg_lambda': 0.008347330496804452}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:43,264]\u001b[0m Trial 24 finished with value: 0.766592926691627 and parameters: {'learning_rate': 0.44143672279454244, 'max_iter': 751, 'max_depth': 12, 'reg_lambda': 0.00363897860652597}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:45,113]\u001b[0m Trial 25 finished with value: 0.766463660921203 and parameters: {'learning_rate': 0.4003071347892459, 'max_iter': 336, 'max_depth': 12, 'reg_lambda': 0.0012115961139542496}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:48,154]\u001b[0m Trial 26 finished with value: 0.7626039497317288 and parameters: {'learning_rate': 0.15624664225913934, 'max_iter': 615, 'max_depth': 12, 'reg_lambda': 0.0021948841675239247}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:49,393]\u001b[0m Trial 27 finished with value: 0.7613112920274888 and parameters: {'learning_rate': 0.2145176085562158, 'max_iter': 225, 'max_depth': 10, 'reg_lambda': 0.0043933861572761764}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:52,629]\u001b[0m Trial 28 finished with value: 0.7650786193699565 and parameters: {'learning_rate': 0.4024611626675861, 'max_iter': 763, 'max_depth': 13, 'reg_lambda': 0.0015757339979827843}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:56:57,659]\u001b[0m Trial 29 finished with value: 0.7634719282012793 and parameters: {'learning_rate': 0.12990159484843256, 'max_iter': 999, 'max_depth': 11, 'reg_lambda': 0.0041271111536237935}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:01,816]\u001b[0m Trial 30 finished with value: 0.7626039497317288 and parameters: {'learning_rate': 0.006718220492985668, 'max_iter': 796, 'max_depth': 13, 'reg_lambda': 0.002031202567457537}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:05,821]\u001b[0m Trial 31 finished with value: 0.7616622074153434 and parameters: {'learning_rate': 0.48929927256264943, 'max_iter': 731, 'max_depth': 15, 'reg_lambda': 0.016899810929927483}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:06,888]\u001b[0m Trial 32 finished with value: 0.529752611813101 and parameters: {'learning_rate': 0.6561029023551969, 'max_iter': 616, 'max_depth': 15, 'reg_lambda': 0.0061376856252737646}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:10,220]\u001b[0m Trial 33 finished with value: 0.7624378020378874 and parameters: {'learning_rate': 0.34280003330642805, 'max_iter': 627, 'max_depth': 16, 'reg_lambda': 0.0032615594435037943}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:11,222]\u001b[0m Trial 34 finished with value: 0.5060944692870258 and parameters: {'learning_rate': 0.9667869182770717, 'max_iter': 504, 'max_depth': 14, 'reg_lambda': 0.016072636568032882}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:15,400]\u001b[0m Trial 35 finished with value: 0.7639152274361405 and parameters: {'learning_rate': 0.6163838247141336, 'max_iter': 768, 'max_depth': 14, 'reg_lambda': 0.04513647358390817}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:17,233]\u001b[0m Trial 36 finished with value: 0.7619576208796088 and parameters: {'learning_rate': 0.07100165984782432, 'max_iter': 354, 'max_depth': 12, 'reg_lambda': 0.010682971142585812}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:19,977]\u001b[0m Trial 37 finished with value: 0.7636011939717033 and parameters: {'learning_rate': 0.23655929911679216, 'max_iter': 534, 'max_depth': 15, 'reg_lambda': 0.005546552861156571}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:24,344]\u001b[0m Trial 38 finished with value: 0.7634719282012793 and parameters: {'learning_rate': 0.04760352475673529, 'max_iter': 935, 'max_depth': 9, 'reg_lambda': 0.02131488489614022}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:25,790]\u001b[0m Trial 39 finished with value: 0.7615698235683368 and parameters: {'learning_rate': 0.45489183531479715, 'max_iter': 278, 'max_depth': 13, 'reg_lambda': 0.0016300901763345527}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:30,265]\u001b[0m Trial 40 finished with value: 0.7633426624308554 and parameters: {'learning_rate': 0.10658543714630923, 'max_iter': 889, 'max_depth': 11, 'reg_lambda': 0.04189602606896424}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:33,003]\u001b[0m Trial 41 finished with value: 0.7633981643544445 and parameters: {'learning_rate': 0.6250867793206554, 'max_iter': 473, 'max_depth': 14, 'reg_lambda': 0.4412327331230913}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:35,057]\u001b[0m Trial 42 finished with value: 0.766980724002899 and parameters: {'learning_rate': 0.34914414185085807, 'max_iter': 383, 'max_depth': 15, 'reg_lambda': 0.528251169231936}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:35,948]\u001b[0m Trial 43 finished with value: 0.763176514737014 and parameters: {'learning_rate': 0.3214637597980201, 'max_iter': 165, 'max_depth': 16, 'reg_lambda': 0.10620743373801392}. Best is trial 21 with value: 0.766980724002899.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:38,101]\u001b[0m Trial 44 finished with value: 0.7674240232377602 and parameters: {'learning_rate': 0.6985021642993975, 'max_iter': 372, 'max_depth': 14, 'reg_lambda': 0.24721828647481794}. Best is trial 44 with value: 0.7674240232377602.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:39,697]\u001b[0m Trial 45 finished with value: 0.7686429170951653 and parameters: {'learning_rate': 0.7017306615279336, 'max_iter': 289, 'max_depth': 14, 'reg_lambda': 0.563723683743928}. Best is trial 45 with value: 0.7686429170951653.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:41,913]\u001b[0m Trial 46 finished with value: 0.7660944836101029 and parameters: {'learning_rate': 0.80629434249325, 'max_iter': 370, 'max_depth': 16, 'reg_lambda': 0.5494510062203593}. Best is trial 45 with value: 0.7686429170951653.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:43,434]\u001b[0m Trial 47 finished with value: 0.7627887174257421 and parameters: {'learning_rate': 0.6861042304099456, 'max_iter': 279, 'max_depth': 14, 'reg_lambda': 0.23931329397583312}. Best is trial 45 with value: 0.7686429170951653.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:44,594]\u001b[0m Trial 48 finished with value: 0.7655956824516524 and parameters: {'learning_rate': 0.1900812951347589, 'max_iter': 225, 'max_depth': 13, 'reg_lambda': 0.5978827019700145}. Best is trial 45 with value: 0.7686429170951653.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:47,220]\u001b[0m Trial 49 finished with value: 0.7604436716348646 and parameters: {'learning_rate': 0.9646560968384724, 'max_iter': 450, 'max_depth': 15, 'reg_lambda': 0.12362069750016068}. Best is trial 45 with value: 0.7686429170951653.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:47,833]\u001b[0m Trial 50 finished with value: 0.7689752124828481 and parameters: {'learning_rate': 0.32915818515815654, 'max_iter': 115, 'max_depth': 14, 'reg_lambda': 0.2748450993928589}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:48,525]\u001b[0m Trial 51 finished with value: 0.7624378020378874 and parameters: {'learning_rate': 0.3275208723838589, 'max_iter': 126, 'max_depth': 14, 'reg_lambda': 0.2699473040937115}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:49,545]\u001b[0m Trial 52 finished with value: 0.7619576208796088 and parameters: {'learning_rate': 0.24980850007267635, 'max_iter': 191, 'max_depth': 16, 'reg_lambda': 0.4215423387242942}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:51,282]\u001b[0m Trial 53 finished with value: 0.7602402839406796 and parameters: {'learning_rate': 0.7514439872912085, 'max_iter': 310, 'max_depth': 15, 'reg_lambda': 0.20713512265385142}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:52,619]\u001b[0m Trial 54 finished with value: 0.7645615562882605 and parameters: {'learning_rate': 0.33351996152580593, 'max_iter': 401, 'max_depth': 5, 'reg_lambda': 0.7659186918960073}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:53,232]\u001b[0m Trial 55 finished with value: 0.5 and parameters: {'learning_rate': 0.00152761956465208, 'max_iter': 115, 'max_depth': 13, 'reg_lambda': 0.35273958843302133}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:54,895]\u001b[0m Trial 56 finished with value: 0.7636566958952926 and parameters: {'learning_rate': 0.5868232689977548, 'max_iter': 305, 'max_depth': 14, 'reg_lambda': 0.14463087317673118}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:55,827]\u001b[0m Trial 57 finished with value: 0.7643767885942473 and parameters: {'learning_rate': 0.05278006607944328, 'max_iter': 175, 'max_depth': 15, 'reg_lambda': 0.5086840895550783}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:57,115]\u001b[0m Trial 58 finished with value: 0.7638597255125513 and parameters: {'learning_rate': 0.11218720132893958, 'max_iter': 251, 'max_depth': 16, 'reg_lambda': 0.30104408589149256}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:57:59,272]\u001b[0m Trial 59 finished with value: 0.7652078851403805 and parameters: {'learning_rate': 0.4272298982926687, 'max_iter': 381, 'max_depth': 14, 'reg_lambda': 0.06563713584205304}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:01,400]\u001b[0m Trial 60 finished with value: 0.7639889912829753 and parameters: {'learning_rate': 0.02479631936887347, 'max_iter': 419, 'max_depth': 13, 'reg_lambda': 0.7237640201528185}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:04,260]\u001b[0m Trial 61 finished with value: 0.7665560447682097 and parameters: {'learning_rate': 0.5215801971468053, 'max_iter': 494, 'max_depth': 15, 'reg_lambda': 0.19230219561064}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:05,032]\u001b[0m Trial 62 finished with value: 0.7689752124828481 and parameters: {'learning_rate': 0.42913113619474386, 'max_iter': 145, 'max_depth': 12, 'reg_lambda': 0.378381035974622}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:06,052]\u001b[0m Trial 63 finished with value: 0.7663343951507791 and parameters: {'learning_rate': 0.3750955045798399, 'max_iter': 193, 'max_depth': 12, 'reg_lambda': 0.9864002904976578}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:06,680]\u001b[0m Trial 64 finished with value: 0.766722192462051 and parameters: {'learning_rate': 0.27525062570501296, 'max_iter': 118, 'max_depth': 11, 'reg_lambda': 0.36536441052990076}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:07,502]\u001b[0m Trial 65 finished with value: 0.7651341212935457 and parameters: {'learning_rate': 0.8459620687167206, 'max_iter': 145, 'max_depth': 13, 'reg_lambda': 0.22952320743796636}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:08,681]\u001b[0m Trial 66 finished with value: 0.764081375129982 and parameters: {'learning_rate': 0.20393845266704025, 'max_iter': 204, 'max_depth': 14, 'reg_lambda': 0.2851563490018947}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:10,060]\u001b[0m Trial 67 finished with value: 0.766205129380355 and parameters: {'learning_rate': 0.5217833579641074, 'max_iter': 255, 'max_depth': 12, 'reg_lambda': 0.4934717950862791}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:11,940]\u001b[0m Trial 68 finished with value: 0.7659097159160898 and parameters: {'learning_rate': 0.6954147162560123, 'max_iter': 341, 'max_depth': 13, 'reg_lambda': 0.15141316056001436}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:12,742]\u001b[0m Trial 69 finished with value: 0.7627332155021528 and parameters: {'learning_rate': 0.08278085127232211, 'max_iter': 149, 'max_depth': 15, 'reg_lambda': 0.70431227027317}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:14,438]\u001b[0m Trial 70 finished with value: 0.7585780908484131 and parameters: {'learning_rate': 0.008692963168696692, 'max_iter': 304, 'max_depth': 10, 'reg_lambda': 0.40117880795329136}. Best is trial 50 with value: 0.7689752124828481.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:15,004]\u001b[0m Trial 71 finished with value: 0.77000933864624 and parameters: {'learning_rate': 0.25627679018516575, 'max_iter': 103, 'max_depth': 11, 'reg_lambda': 0.33569768026131186}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:15,551]\u001b[0m Trial 72 finished with value: 0.76240092011447 and parameters: {'learning_rate': 0.41195757669862565, 'max_iter': 100, 'max_depth': 11, 'reg_lambda': 0.5984595552326495}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:17,815]\u001b[0m Trial 73 finished with value: 0.7624378020378874 and parameters: {'learning_rate': 0.2752401762600644, 'max_iter': 438, 'max_depth': 12, 'reg_lambda': 0.30945088832884504}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:18,592]\u001b[0m Trial 74 finished with value: 0.7644691724412539 and parameters: {'learning_rate': 0.15154276012060425, 'max_iter': 136, 'max_depth': 14, 'reg_lambda': 0.24983691423115983}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:19,583]\u001b[0m Trial 75 finished with value: 0.762659451655318 and parameters: {'learning_rate': 0.5976364432552023, 'max_iter': 168, 'max_depth': 10, 'reg_lambda': 0.07674984679307648}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:20,772]\u001b[0m Trial 76 finished with value: 0.7604064316345209 and parameters: {'learning_rate': 0.4634945301134936, 'max_iter': 225, 'max_depth': 11, 'reg_lambda': 0.17270050504095638}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:22,638]\u001b[0m Trial 77 finished with value: 0.77000933864624 and parameters: {'learning_rate': 0.23349393085073555, 'max_iter': 366, 'max_depth': 12, 'reg_lambda': 0.11887141290832472}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:25,052]\u001b[0m Trial 78 finished with value: 0.7634719282012793 and parameters: {'learning_rate': 0.18057578972544708, 'max_iter': 369, 'max_depth': 12, 'reg_lambda': 0.10956733013609635}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:27,510]\u001b[0m Trial 79 finished with value: 0.7663712770741964 and parameters: {'learning_rate': 0.22046876857435135, 'max_iter': 475, 'max_depth': 13, 'reg_lambda': 0.4493866108036894}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:30,644]\u001b[0m Trial 80 finished with value: 0.7654664166812284 and parameters: {'learning_rate': 0.29619438202787485, 'max_iter': 566, 'max_depth': 11, 'reg_lambda': 0.36169242966232934}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:32,824]\u001b[0m Trial 81 finished with value: 0.763822843589134 and parameters: {'learning_rate': 0.36600131315564327, 'max_iter': 418, 'max_depth': 12, 'reg_lambda': 0.12408187240555965}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:34,606]\u001b[0m Trial 82 finished with value: 0.7659097159160898 and parameters: {'learning_rate': 0.7449173034531082, 'max_iter': 332, 'max_depth': 9, 'reg_lambda': 0.3152082733412596}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:36,648]\u001b[0m Trial 83 finished with value: 0.7680703520898801 and parameters: {'learning_rate': 0.530033124127682, 'max_iter': 355, 'max_depth': 14, 'reg_lambda': 0.2159775842143319}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:38,802]\u001b[0m Trial 84 finished with value: 0.7645615562882605 and parameters: {'learning_rate': 0.5141789742051747, 'max_iter': 391, 'max_depth': 13, 'reg_lambda': 0.21149774309619054}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:40,746]\u001b[0m Trial 85 finished with value: 0.7611820262570649 and parameters: {'learning_rate': 0.13625974902267804, 'max_iter': 350, 'max_depth': 14, 'reg_lambda': 0.6181876560567366}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:43,186]\u001b[0m Trial 86 finished with value: 0.758596710848585 and parameters: {'learning_rate': 0.8469756570647893, 'max_iter': 446, 'max_depth': 12, 'reg_lambda': 0.5024172116361244}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:44,783]\u001b[0m Trial 87 finished with value: 0.7655956824516524 and parameters: {'learning_rate': 0.38307439669596216, 'max_iter': 289, 'max_depth': 14, 'reg_lambda': 0.7636902733919619}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:46,242]\u001b[0m Trial 88 finished with value: 0.7659834797629245 and parameters: {'learning_rate': 0.2541322491313434, 'max_iter': 255, 'max_depth': 13, 'reg_lambda': 0.25004567816928364}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:47,719]\u001b[0m Trial 89 finished with value: 0.7308593559771632 and parameters: {'learning_rate': 0.9771046250318054, 'max_iter': 529, 'max_depth': 14, 'reg_lambda': 0.05121786594330185}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:49,408]\u001b[0m Trial 90 finished with value: 0.7639521093595579 and parameters: {'learning_rate': 0.33433073783353706, 'max_iter': 321, 'max_depth': 13, 'reg_lambda': 0.17432012176145037}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:50,165]\u001b[0m Trial 91 finished with value: 0.7655219186048178 and parameters: {'learning_rate': 0.5857550049807033, 'max_iter': 129, 'max_depth': 16, 'reg_lambda': 0.40950854972477907}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:52,444]\u001b[0m Trial 92 finished with value: 0.7615329416449194 and parameters: {'learning_rate': 0.4563681613560336, 'max_iter': 402, 'max_depth': 15, 'reg_lambda': 0.03208170253278945}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:53,038]\u001b[0m Trial 93 finished with value: 0.7577842343026238 and parameters: {'learning_rate': 0.6890515261431137, 'max_iter': 102, 'max_depth': 15, 'reg_lambda': 0.09397926676266209}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:54,007]\u001b[0m Trial 94 finished with value: 0.7684581494011521 and parameters: {'learning_rate': 0.546279103793233, 'max_iter': 173, 'max_depth': 15, 'reg_lambda': 0.13749391870496078}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:56,136]\u001b[0m Trial 95 finished with value: 0.7629548651195834 and parameters: {'learning_rate': 0.2954710268945944, 'max_iter': 362, 'max_depth': 14, 'reg_lambda': 0.330266539391322}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:57,132]\u001b[0m Trial 96 finished with value: 0.7644322905178366 and parameters: {'learning_rate': 0.5363309934489792, 'max_iter': 180, 'max_depth': 15, 'reg_lambda': 0.2690185503941501}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:57,828]\u001b[0m Trial 97 finished with value: 0.763435046277862 and parameters: {'learning_rate': 0.24217537729669655, 'max_iter': 148, 'max_depth': 8, 'reg_lambda': 0.1384063190408934}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:58:59,057]\u001b[0m Trial 98 finished with value: 0.7640444932065645 and parameters: {'learning_rate': 0.4158751994368808, 'max_iter': 222, 'max_depth': 14, 'reg_lambda': 0.8349183420716267}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 01:59:01,459]\u001b[0m Trial 99 finished with value: 0.7573223150675906 and parameters: {'learning_rate': 0.0039002933815692354, 'max_iter': 426, 'max_depth': 13, 'reg_lambda': 0.21632911564823923}. Best is trial 71 with value: 0.77000933864624.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sampler = TPESampler(seed = 39)\n",
    "study = optuna.create_study(\n",
    "    study_name = \"hgb_parameter_opt\",\n",
    "    direction = \"maximize\",\n",
    "    sampler = sampler)\n",
    "study.optimize(objective, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6775df09-a42e-4c48-9e1d-b79c7b7bcf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score : 0.77000933864624\n",
      "Best trial : {'learning_rate': 0.25627679018516575, 'max_iter': 103, 'max_depth': 11, 'reg_lambda': 0.33569768026131186}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score :\", study.best_value)\n",
    "print(\"Best trial :\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7fe8d8e6-a563-4be4-9430-ff9eaa26e6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095, 2)\n",
      "(9866, 2)\n",
      "training model for CV #1\n",
      "training model for CV #2\n",
      "training model for CV #3\n",
      "training model for CV #4\n",
      "training model for CV #5\n"
     ]
    }
   ],
   "source": [
    "n_fold = 5\n",
    "cv = StratifiedKFold(n_splits = n_fold, shuffle = True, random_state = 39)\n",
    "\n",
    "hgb_val = np.zeros((X_train.shape[0], 2))\n",
    "hgb_partrain = np.zeros((X_partrain.shape[0], 2))\n",
    "\n",
    "print(hgb_val.shape)\n",
    "print(hgb_partrain.shape)\n",
    "\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(X_train, y_train), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    optuna_hgb = HistGradientBoostingClassifier(\n",
    "        random_state = 39,\n",
    "        learning_rate = 0.25627679018516575, \n",
    "        max_iter = 103,\n",
    "        l2_regularization = 0.33569768026131186)\n",
    "\n",
    "    optuna_hgb.fit(X_train.loc[i_trn, :], y_train[i_trn])\n",
    "\n",
    "    hgb_val[i_val, :] = optuna_hgb.predict_proba(X_train.loc[i_val, :])\n",
    "    hgb_partrain += optuna_hgb.predict_proba(X_partrain) / n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dbbf7869-ec31-4b2d-b968-d25aa6c2f621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095, 2)\n",
      "(14095, 26)\n"
     ]
    }
   ],
   "source": [
    "print(hgb_val.shape)\n",
    "\n",
    "train_teacher['Hgb_prob1'] = hgb_val[:, 1]\n",
    "print(train_teacher.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23917f18-02ed-4db3-89fe-3536d2d101d0",
   "metadata": {},
   "source": [
    "########################################################################################  \n",
    "########################################################################################  \n",
    "# 6. Student Model\n",
    "########################################################################################  \n",
    "########################################################################################  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a69f18c2-2fd9-4487-8208-a592ce10a599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ANONYMOUS_1', 'ANONYMOUS_2', 'AG', 'CO', 'CR', 'CU', 'FE', 'H2O', 'MN',\n",
       "       'MO', 'NI', 'PQINDEX', 'TI', 'V', 'V40', 'ZN', 'Y_LABEL', 'AL', 'BA',\n",
       "       'COMPONENT_ARBITRARY_category', 'YEAR_category', 'Cat_prob1',\n",
       "       'Lgb_prob1', 'Rf_prob1', 'Gbm_prob1', 'Hgb_prob1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_teacher.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d06a8acc-98bd-42c7-b858-5c1a2971c3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095, 22)\n",
      "Index(['ANONYMOUS_1', 'ANONYMOUS_2', 'AG', 'CO', 'CR', 'CU', 'FE', 'H2O', 'MN',\n",
      "       'MO', 'NI', 'PQINDEX', 'TI', 'V', 'V40', 'ZN', 'Y_LABEL', 'AL', 'BA',\n",
      "       'COMPONENT_ARBITRARY_category', 'YEAR_category', 'model1_prob'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train3['model1_prob'] = (train_teacher['Cat_prob1'] + train_teacher['Rf_prob1']) / 2\n",
    "print(train3.shape)\n",
    "print(train3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "65c12d10-4f16-4064-a4e2-f01f2f1b9d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095, 18)\n",
      "(14095,)\n"
     ]
    }
   ],
   "source": [
    "X_train2 = train3.drop(['AL', 'BA', 'Y_LABEL', 'model1_prob'], axis = 1)\n",
    "y_train2 = train3['model1_prob']\n",
    "print(X_train2.shape)\n",
    "print(y_train2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "7185b467-ab88-407e-8da8-15f30503f0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9866, 18)\n",
      "(4229, 18)\n",
      "(9866,)\n",
      "(4229,)\n"
     ]
    }
   ],
   "source": [
    "X_partrain, X_val, y_partrain, y_val = train_test_split(X_train2, y_train2, test_size = 0.3, random_state = 39)\n",
    "print(X_partrain.shape)\n",
    "print(X_val.shape)\n",
    "print(y_partrain.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "0d4c8559-95b1-4937-a457-93ffdbe6c352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COMPONENT_ARBITRARY_category', 'YEAR_category']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "917d96df-0b80-4746-88ca-079a1e99df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.core import CatBoostRegressor\n",
    "def objective(trial : Trial) -> float :\n",
    "\n",
    "    params_cat = {\n",
    "        \"random_state\" : 39,\n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.001, 1),\n",
    "        \"n_estimators\" : trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\" : trial.suggest_int(\"max_depth\", 3, 10)\n",
    "  }\n",
    "    \n",
    "    model = CatBoostRegressor(**params_cat)\n",
    "    model.fit(X_partrain, y_partrain, eval_set = [(X_val, y_val)],\n",
    "              early_stopping_rounds = 100, cat_features = categorical_features, verbose = False)\n",
    "\n",
    "    cat_pred = model.predict(X_val)\n",
    "    MAE = mean_absolute_error(y_val, cat_pred)\n",
    "    \n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "82024ac0-4e18-4508-b1f5-4dfaa6bd60b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-11 08:09:01,820]\u001b[0m A new study created in memory with name: cat_parameter_opt\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:09:09,112]\u001b[0m Trial 0 finished with value: 0.0795696415207403 and parameters: {'learning_rate': 0.04371872304807245, 'n_estimators': 818, 'max_depth': 9}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:09:13,711]\u001b[0m Trial 1 finished with value: 0.08248199234676559 and parameters: {'learning_rate': 0.002323537042351288, 'n_estimators': 642, 'max_depth': 7}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:09:18,982]\u001b[0m Trial 2 finished with value: 0.07993565858450426 and parameters: {'learning_rate': 0.024644795423723085, 'n_estimators': 524, 'max_depth': 8}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:09:21,521]\u001b[0m Trial 3 finished with value: 0.08344865191672474 and parameters: {'learning_rate': 0.5984000779343428, 'n_estimators': 834, 'max_depth': 10}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:09:23,667]\u001b[0m Trial 4 finished with value: 0.08263241964820424 and parameters: {'learning_rate': 0.5737932383737886, 'n_estimators': 473, 'max_depth': 9}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:09:24,196]\u001b[0m Trial 5 finished with value: 0.08302899600226948 and parameters: {'learning_rate': 0.68989080483343, 'n_estimators': 665, 'max_depth': 5}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:09:26,078]\u001b[0m Trial 6 finished with value: 0.08049754230998964 and parameters: {'learning_rate': 0.05984842261391979, 'n_estimators': 875, 'max_depth': 3}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:09:26,642]\u001b[0m Trial 7 finished with value: 0.08169138802131748 and parameters: {'learning_rate': 0.36677155109656834, 'n_estimators': 748, 'max_depth': 5}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:09:30,142]\u001b[0m Trial 8 finished with value: 0.07989679671106759 and parameters: {'learning_rate': 0.028590346350381008, 'n_estimators': 860, 'max_depth': 7}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:09:32,063]\u001b[0m Trial 9 finished with value: 0.08313697626088024 and parameters: {'learning_rate': 0.0029609935336908696, 'n_estimators': 574, 'max_depth': 4}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:09:36,408]\u001b[0m Trial 10 finished with value: 0.0799062054259148 and parameters: {'learning_rate': 0.09900330892141677, 'n_estimators': 208, 'max_depth': 10}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:09:41,748]\u001b[0m Trial 11 finished with value: 0.08012453424589752 and parameters: {'learning_rate': 0.013669010609763105, 'n_estimators': 964, 'max_depth': 7}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:09:51,521]\u001b[0m Trial 12 finished with value: 0.07986665043557101 and parameters: {'learning_rate': 0.009308627529030805, 'n_estimators': 1000, 'max_depth': 8}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:10:08,716]\u001b[0m Trial 13 finished with value: 0.07981570629074362 and parameters: {'learning_rate': 0.009585987279267858, 'n_estimators': 994, 'max_depth': 9}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:10:14,223]\u001b[0m Trial 14 finished with value: 0.08186847029479732 and parameters: {'learning_rate': 0.006012518544544048, 'n_estimators': 289, 'max_depth': 9}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:10:17,102]\u001b[0m Trial 15 finished with value: 0.08056194905642622 and parameters: {'learning_rate': 0.12672642506423576, 'n_estimators': 746, 'max_depth': 9}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:10:26,046]\u001b[0m Trial 16 finished with value: 0.08290708402562898 and parameters: {'learning_rate': 0.001277742744700719, 'n_estimators': 921, 'max_depth': 8}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:10:26,931]\u001b[0m Trial 17 finished with value: 0.08140342760883161 and parameters: {'learning_rate': 0.20019372779662345, 'n_estimators': 415, 'max_depth': 6}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:10:32,578]\u001b[0m Trial 18 finished with value: 0.07974548866775748 and parameters: {'learning_rate': 0.051382567012890776, 'n_estimators': 743, 'max_depth': 10}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:10:39,411]\u001b[0m Trial 19 finished with value: 0.07980268722419337 and parameters: {'learning_rate': 0.050802804942102084, 'n_estimators': 725, 'max_depth': 10}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:10:42,169]\u001b[0m Trial 20 finished with value: 0.0809919440248839 and parameters: {'learning_rate': 0.22750736895891469, 'n_estimators': 807, 'max_depth': 10}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:10:48,925]\u001b[0m Trial 21 finished with value: 0.0798373872701147 and parameters: {'learning_rate': 0.04969908614442445, 'n_estimators': 636, 'max_depth': 10}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:10:54,871]\u001b[0m Trial 22 finished with value: 0.08024018224034868 and parameters: {'learning_rate': 0.06372915478813007, 'n_estimators': 762, 'max_depth': 10}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:11:06,001]\u001b[0m Trial 23 finished with value: 0.07983039488471956 and parameters: {'learning_rate': 0.017777824325374347, 'n_estimators': 691, 'max_depth': 9}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:11:09,137]\u001b[0m Trial 24 finished with value: 0.07971499974150116 and parameters: {'learning_rate': 0.0390362131808893, 'n_estimators': 569, 'max_depth': 8}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:11:10,771]\u001b[0m Trial 25 finished with value: 0.0803177184092938 and parameters: {'learning_rate': 0.10878676582435118, 'n_estimators': 382, 'max_depth': 8}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:11:14,243]\u001b[0m Trial 26 finished with value: 0.07985371389883568 and parameters: {'learning_rate': 0.034300270204867374, 'n_estimators': 562, 'max_depth': 8}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:11:17,550]\u001b[0m Trial 27 finished with value: 0.07993832970907154 and parameters: {'learning_rate': 0.018622619554096432, 'n_estimators': 596, 'max_depth': 6}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:11:23,835]\u001b[0m Trial 28 finished with value: 0.08012546533813016 and parameters: {'learning_rate': 0.036343132868367725, 'n_estimators': 496, 'max_depth': 9}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:11:28,316]\u001b[0m Trial 29 finished with value: 0.0809672597207356 and parameters: {'learning_rate': 0.0053638013458125, 'n_estimators': 642, 'max_depth': 7}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:11:29,091]\u001b[0m Trial 30 finished with value: 0.080210056956856 and parameters: {'learning_rate': 0.1840007667889366, 'n_estimators': 104, 'max_depth': 8}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:11:33,285]\u001b[0m Trial 31 finished with value: 0.08020949656394011 and parameters: {'learning_rate': 0.080340242693143, 'n_estimators': 706, 'max_depth': 10}. Best is trial 0 with value: 0.0795696415207403.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:11:40,114]\u001b[0m Trial 32 finished with value: 0.07956802891734764 and parameters: {'learning_rate': 0.03884954002281173, 'n_estimators': 796, 'max_depth': 9}. Best is trial 32 with value: 0.07956802891734764.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:11:50,097]\u001b[0m Trial 33 finished with value: 0.07971650098139069 and parameters: {'learning_rate': 0.02349054629543768, 'n_estimators': 803, 'max_depth': 9}. Best is trial 32 with value: 0.07956802891734764.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:11:57,172]\u001b[0m Trial 34 finished with value: 0.07997826515050656 and parameters: {'learning_rate': 0.023506826244427768, 'n_estimators': 823, 'max_depth': 9}. Best is trial 32 with value: 0.07956802891734764.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:12:06,050]\u001b[0m Trial 35 finished with value: 0.07969622537125673 and parameters: {'learning_rate': 0.012835998866017889, 'n_estimators': 899, 'max_depth': 8}. Best is trial 32 with value: 0.07956802891734764.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:12:15,008]\u001b[0m Trial 36 finished with value: 0.0800488104034621 and parameters: {'learning_rate': 0.007961735410379053, 'n_estimators': 913, 'max_depth': 8}. Best is trial 32 with value: 0.07956802891734764.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:12:20,039]\u001b[0m Trial 37 finished with value: 0.08013784856557428 and parameters: {'learning_rate': 0.011924034708656802, 'n_estimators': 919, 'max_depth': 6}. Best is trial 32 with value: 0.07956802891734764.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:12:26,032]\u001b[0m Trial 38 finished with value: 0.08108027427197903 and parameters: {'learning_rate': 0.003974233041318652, 'n_estimators': 863, 'max_depth': 7}. Best is trial 32 with value: 0.07956802891734764.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:12:34,410]\u001b[0m Trial 39 finished with value: 0.07971952897980832 and parameters: {'learning_rate': 0.01570820080699, 'n_estimators': 889, 'max_depth': 8}. Best is trial 32 with value: 0.07956802891734764.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:12:38,150]\u001b[0m Trial 40 finished with value: 0.0798133643112741 and parameters: {'learning_rate': 0.0309149509158992, 'n_estimators': 953, 'max_depth': 7}. Best is trial 32 with value: 0.07956802891734764.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:12:48,090]\u001b[0m Trial 41 finished with value: 0.07980323411236685 and parameters: {'learning_rate': 0.021347735055439406, 'n_estimators': 789, 'max_depth': 9}. Best is trial 32 with value: 0.07956802891734764.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:12:54,154]\u001b[0m Trial 42 finished with value: 0.08003105976332907 and parameters: {'learning_rate': 0.035210216454526315, 'n_estimators': 841, 'max_depth': 9}. Best is trial 32 with value: 0.07956802891734764.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:12:55,997]\u001b[0m Trial 43 finished with value: 0.08031221462196754 and parameters: {'learning_rate': 0.06833627895974455, 'n_estimators': 809, 'max_depth': 8}. Best is trial 32 with value: 0.07956802891734764.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:12:57,445]\u001b[0m Trial 44 finished with value: 0.08052207120673154 and parameters: {'learning_rate': 0.04164782054243114, 'n_estimators': 603, 'max_depth': 3}. Best is trial 32 with value: 0.07956802891734764.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:13:06,670]\u001b[0m Trial 45 finished with value: 0.07968471356218103 and parameters: {'learning_rate': 0.02445093068241384, 'n_estimators': 676, 'max_depth': 9}. Best is trial 32 with value: 0.07956802891734764.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:13:08,902]\u001b[0m Trial 46 finished with value: 0.08044300768589424 and parameters: {'learning_rate': 0.07880496059609507, 'n_estimators': 528, 'max_depth': 8}. Best is trial 32 with value: 0.07956802891734764.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:13:21,110]\u001b[0m Trial 47 finished with value: 0.07961771068493931 and parameters: {'learning_rate': 0.013917333446199161, 'n_estimators': 677, 'max_depth': 9}. Best is trial 32 with value: 0.07956802891734764.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:13:33,488]\u001b[0m Trial 48 finished with value: 0.08000966357334753 and parameters: {'learning_rate': 0.010421151179564752, 'n_estimators': 678, 'max_depth': 9}. Best is trial 32 with value: 0.07956802891734764.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:13:36,195]\u001b[0m Trial 49 finished with value: 0.08167442276762378 and parameters: {'learning_rate': 0.006279346937941668, 'n_estimators': 784, 'max_depth': 4}. Best is trial 32 with value: 0.07956802891734764.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:13:48,880]\u001b[0m Trial 50 finished with value: 0.07995472841980499 and parameters: {'learning_rate': 0.012442639727408299, 'n_estimators': 875, 'max_depth': 9}. Best is trial 32 with value: 0.07956802891734764.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:13:57,653]\u001b[0m Trial 51 finished with value: 0.0793523289383799 and parameters: {'learning_rate': 0.027136873126814776, 'n_estimators': 652, 'max_depth': 9}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:14:04,311]\u001b[0m Trial 52 finished with value: 0.08041714828618 and parameters: {'learning_rate': 0.025867581392056953, 'n_estimators': 655, 'max_depth': 9}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:14:17,134]\u001b[0m Trial 53 finished with value: 0.0797464732970117 and parameters: {'learning_rate': 0.01595869203197031, 'n_estimators': 724, 'max_depth': 10}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:14:31,274]\u001b[0m Trial 54 finished with value: 0.08011616738319066 and parameters: {'learning_rate': 0.0074709563022148495, 'n_estimators': 766, 'max_depth': 9}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:14:44,419]\u001b[0m Trial 55 finished with value: 0.08234327533062478 and parameters: {'learning_rate': 0.0020997179480296713, 'n_estimators': 604, 'max_depth': 10}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:14:53,312]\u001b[0m Trial 56 finished with value: 0.07953499548597531 and parameters: {'learning_rate': 0.028219590398629264, 'n_estimators': 636, 'max_depth': 9}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:14:56,951]\u001b[0m Trial 57 finished with value: 0.08023662609499128 and parameters: {'learning_rate': 0.14350623158871598, 'n_estimators': 448, 'max_depth': 10}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:15:06,433]\u001b[0m Trial 58 finished with value: 0.07954276286076513 and parameters: {'learning_rate': 0.02742449742385065, 'n_estimators': 630, 'max_depth': 9}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:15:12,266]\u001b[0m Trial 59 finished with value: 0.08029888981107657 and parameters: {'learning_rate': 0.05323207158308971, 'n_estimators': 525, 'max_depth': 9}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:15:18,727]\u001b[0m Trial 60 finished with value: 0.07997620432254901 and parameters: {'learning_rate': 0.04434578946113029, 'n_estimators': 614, 'max_depth': 10}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:15:26,661]\u001b[0m Trial 61 finished with value: 0.07969007909151087 and parameters: {'learning_rate': 0.029259019493796227, 'n_estimators': 659, 'max_depth': 9}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:15:38,041]\u001b[0m Trial 62 finished with value: 0.07967407280633303 and parameters: {'learning_rate': 0.019276890093416117, 'n_estimators': 691, 'max_depth': 9}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:15:49,432]\u001b[0m Trial 63 finished with value: 0.07973070272640351 and parameters: {'learning_rate': 0.01852935362629751, 'n_estimators': 711, 'max_depth': 9}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:15:51,978]\u001b[0m Trial 64 finished with value: 0.08563313211620224 and parameters: {'learning_rate': 0.8793030538477884, 'n_estimators': 635, 'max_depth': 10}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:16:00,123]\u001b[0m Trial 65 finished with value: 0.07998113376088206 and parameters: {'learning_rate': 0.020569307393844015, 'n_estimators': 741, 'max_depth': 9}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:16:02,752]\u001b[0m Trial 66 finished with value: 0.08027634430292113 and parameters: {'learning_rate': 0.027221238383165414, 'n_estimators': 692, 'max_depth': 5}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:16:05,221]\u001b[0m Trial 67 finished with value: 0.08051135815563917 and parameters: {'learning_rate': 0.060865903922847374, 'n_estimators': 579, 'max_depth': 8}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:16:09,789]\u001b[0m Trial 68 finished with value: 0.0804429807032376 and parameters: {'learning_rate': 0.08849674703516044, 'n_estimators': 544, 'max_depth': 10}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:16:16,003]\u001b[0m Trial 69 finished with value: 0.07961981799801889 and parameters: {'learning_rate': 0.015077305023540901, 'n_estimators': 626, 'max_depth': 8}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:16:20,948]\u001b[0m Trial 70 finished with value: 0.0801420117365838 and parameters: {'learning_rate': 0.015004217700683897, 'n_estimators': 497, 'max_depth': 8}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:16:32,753]\u001b[0m Trial 71 finished with value: 0.07999192582969235 and parameters: {'learning_rate': 0.010018179997853543, 'n_estimators': 626, 'max_depth': 9}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:16:38,949]\u001b[0m Trial 72 finished with value: 0.0798044932588295 and parameters: {'learning_rate': 0.041020189524201243, 'n_estimators': 583, 'max_depth': 9}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:16:46,906]\u001b[0m Trial 73 finished with value: 0.07975844989157557 and parameters: {'learning_rate': 0.032596492279729564, 'n_estimators': 764, 'max_depth': 9}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:16:53,236]\u001b[0m Trial 74 finished with value: 0.07964034994746005 and parameters: {'learning_rate': 0.019212336422633494, 'n_estimators': 694, 'max_depth': 8}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:16:55,718]\u001b[0m Trial 75 finished with value: 0.07952673489298158 and parameters: {'learning_rate': 0.04624248344099222, 'n_estimators': 838, 'max_depth': 7}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:16:58,931]\u001b[0m Trial 76 finished with value: 0.07978060492910212 and parameters: {'learning_rate': 0.0512162323276286, 'n_estimators': 845, 'max_depth': 7}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:17:02,554]\u001b[0m Trial 77 finished with value: 0.07975916418995149 and parameters: {'learning_rate': 0.030176358141709818, 'n_estimators': 946, 'max_depth': 6}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:17:06,596]\u001b[0m Trial 78 finished with value: 0.08005930149380491 and parameters: {'learning_rate': 0.0685188369250272, 'n_estimators': 554, 'max_depth': 8}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:17:08,008]\u001b[0m Trial 79 finished with value: 0.08012315979419873 and parameters: {'learning_rate': 0.11893240853883384, 'n_estimators': 733, 'max_depth': 7}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:17:12,545]\u001b[0m Trial 80 finished with value: 0.07984466222188558 and parameters: {'learning_rate': 0.036540972954807044, 'n_estimators': 652, 'max_depth': 8}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:17:17,344]\u001b[0m Trial 81 finished with value: 0.07987314348698803 and parameters: {'learning_rate': 0.022924850272252793, 'n_estimators': 703, 'max_depth': 7}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:17:24,941]\u001b[0m Trial 82 finished with value: 0.07976214615521407 and parameters: {'learning_rate': 0.015271745599918271, 'n_estimators': 779, 'max_depth': 8}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:17:36,725]\u001b[0m Trial 83 finished with value: 0.07987689096036438 and parameters: {'learning_rate': 0.011352425973286093, 'n_estimators': 632, 'max_depth': 9}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:17:40,838]\u001b[0m Trial 84 finished with value: 0.07976118738844673 and parameters: {'learning_rate': 0.047183350421565275, 'n_estimators': 821, 'max_depth': 8}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:17:53,229]\u001b[0m Trial 85 finished with value: 0.07983656731522668 and parameters: {'learning_rate': 0.008961142808545885, 'n_estimators': 670, 'max_depth': 9}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:17:54,475]\u001b[0m Trial 86 finished with value: 0.08112228452508007 and parameters: {'learning_rate': 0.33111329751652485, 'n_estimators': 754, 'max_depth': 8}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:17:58,404]\u001b[0m Trial 87 finished with value: 0.07963065600716225 and parameters: {'learning_rate': 0.027317863332433707, 'n_estimators': 721, 'max_depth': 7}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:18:03,411]\u001b[0m Trial 88 finished with value: 0.07972775403224797 and parameters: {'learning_rate': 0.028485663161001, 'n_estimators': 721, 'max_depth': 7}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:18:06,417]\u001b[0m Trial 89 finished with value: 0.07990895067542134 and parameters: {'learning_rate': 0.03983359701542289, 'n_estimators': 839, 'max_depth': 6}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:18:12,160]\u001b[0m Trial 90 finished with value: 0.07993397310262441 and parameters: {'learning_rate': 0.013848791848512796, 'n_estimators': 795, 'max_depth': 7}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:18:16,564]\u001b[0m Trial 91 finished with value: 0.0798738483226072 and parameters: {'learning_rate': 0.021506595269857962, 'n_estimators': 678, 'max_depth': 7}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:18:18,860]\u001b[0m Trial 92 finished with value: 0.07970721283683635 and parameters: {'learning_rate': 0.05650688259212929, 'n_estimators': 592, 'max_depth': 6}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:18:26,041]\u001b[0m Trial 93 finished with value: 0.08015365395546184 and parameters: {'learning_rate': 0.025303714562317444, 'n_estimators': 860, 'max_depth': 9}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:18:29,132]\u001b[0m Trial 94 finished with value: 0.07999179441018586 and parameters: {'learning_rate': 0.034065727528869806, 'n_estimators': 618, 'max_depth': 8}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:18:35,731]\u001b[0m Trial 95 finished with value: 0.08006809095413113 and parameters: {'learning_rate': 0.01789260728240396, 'n_estimators': 347, 'max_depth': 9}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:18:41,602]\u001b[0m Trial 96 finished with value: 0.07973894351112006 and parameters: {'learning_rate': 0.017633967505246588, 'n_estimators': 654, 'max_depth': 8}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:18:47,585]\u001b[0m Trial 97 finished with value: 0.08017164790003944 and parameters: {'learning_rate': 0.0473844147495108, 'n_estimators': 695, 'max_depth': 9}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:18:52,866]\u001b[0m Trial 98 finished with value: 0.0801992254031226 and parameters: {'learning_rate': 0.0698387888829101, 'n_estimators': 774, 'max_depth': 10}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 08:19:02,777]\u001b[0m Trial 99 finished with value: 0.07961614174617872 and parameters: {'learning_rate': 0.02435871473802268, 'n_estimators': 739, 'max_depth': 9}. Best is trial 51 with value: 0.0793523289383799.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sampler = TPESampler(seed = 39)\n",
    "study = optuna.create_study(\n",
    "    study_name = \"cat_parameter_opt\",\n",
    "    direction = \"minimize\",\n",
    "    sampler = sampler)\n",
    "study.optimize(objective, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "42bc6532-697d-4dc0-8ce4-7d0222ae8762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score : 0.0793523289383799\n",
      "Best trial : {'learning_rate': 0.027136873126814776, 'n_estimators': 652, 'max_depth': 9}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score :\", study.best_value)\n",
    "print(\"Best trial :\", study.best_trial.params) \n",
    "\n",
    "# 최고 : 'learning_rate': 0.01310047432090872, 'n_estimators': 848, 'max_depth': 9 -> 0.0812793649948276\n",
    "# LGB : 'learning_rate': 0.0277239359067536, 'n_estimators': 809, 'max_depth': 10 -> 0.0949505112796726\n",
    "# RF : 'learning_rate': 0.01846197377069944, 'n_estimators': 904, 'max_depth': 6 -> 0.07889456904387222\n",
    "# GBM : 'learning_rate': 0.0035644851302199143, 'n_estimators': 943, 'max_depth': 10 -> 0.0825830066358257\n",
    "# HGB : 'learning_rate': 0.06936407648125087, 'n_estimators': 503, 'max_depth': 6 -> 0.0832921275577305\n",
    "# RF + HGB : 'learning_rate': 0.027136873126814776, 'n_estimators': 652, 'max_depth': 9 -> 0.0793523289383799"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4a25885a-108b-44dc-9efd-9a8fa816fbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095,)\n",
      "(6041,)\n",
      "training model for CV #1\n",
      "training model for CV #2\n",
      "training model for CV #3\n",
      "training model for CV #4\n",
      "training model for CV #5\n"
     ]
    }
   ],
   "source": [
    "n_fold = 5\n",
    "cv = KFold(n_splits = n_fold, shuffle = True, random_state = 39)\n",
    "\n",
    "cat_val = np.zeros((X_train2.shape[0]))\n",
    "cat_test = np.zeros((X_test.shape[0]))\n",
    "\n",
    "print(cat_val.shape)\n",
    "print(cat_test.shape)\n",
    "\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(X_train2, y_train2), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    optuna_cat = CatBoostRegressor(\n",
    "        random_state = 39,\n",
    "        learning_rate = 0.01846197377069944, \n",
    "        n_estimators = 904, \n",
    "        max_depth = 6)\n",
    "\n",
    "    optuna_cat.fit(X_train2.loc[i_trn, :], y_train2[i_trn], verbose = False, \n",
    "                   cat_features = categorical_features, early_stopping_rounds = 100)\n",
    "\n",
    "    cat_val[i_val] = optuna_cat.predict(X_train2.loc[i_val, :])\n",
    "    cat_test += optuna_cat.predict(X_test) / n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "417beea3-e4d7-4edb-bd4e-1e784506be93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>score</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.157286</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12891</td>\n",
       "      <td>1203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.159368</td>\n",
       "      <td>224</td>\n",
       "      <td>2</td>\n",
       "      <td>12668</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.175220</td>\n",
       "      <td>2077</td>\n",
       "      <td>49</td>\n",
       "      <td>10815</td>\n",
       "      <td>1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.199084</td>\n",
       "      <td>4859</td>\n",
       "      <td>182</td>\n",
       "      <td>8033</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.226240</td>\n",
       "      <td>7423</td>\n",
       "      <td>352</td>\n",
       "      <td>5469</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.248428</td>\n",
       "      <td>9498</td>\n",
       "      <td>551</td>\n",
       "      <td>3394</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.256775</td>\n",
       "      <td>10911</td>\n",
       "      <td>734</td>\n",
       "      <td>1981</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.243053</td>\n",
       "      <td>11724</td>\n",
       "      <td>875</td>\n",
       "      <td>1168</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.224555</td>\n",
       "      <td>12150</td>\n",
       "      <td>957</td>\n",
       "      <td>742</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.209584</td>\n",
       "      <td>12395</td>\n",
       "      <td>1004</td>\n",
       "      <td>497</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.175044</td>\n",
       "      <td>12552</td>\n",
       "      <td>1055</td>\n",
       "      <td>340</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.139657</td>\n",
       "      <td>12683</td>\n",
       "      <td>1097</td>\n",
       "      <td>209</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.106169</td>\n",
       "      <td>12775</td>\n",
       "      <td>1129</td>\n",
       "      <td>117</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.076104</td>\n",
       "      <td>12831</td>\n",
       "      <td>1153</td>\n",
       "      <td>61</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.065523</td>\n",
       "      <td>12855</td>\n",
       "      <td>1161</td>\n",
       "      <td>37</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.056782</td>\n",
       "      <td>12863</td>\n",
       "      <td>1167</td>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.050996</td>\n",
       "      <td>12872</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>12876</td>\n",
       "      <td>1172</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.043513</td>\n",
       "      <td>12881</td>\n",
       "      <td>1176</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.042071</td>\n",
       "      <td>12885</td>\n",
       "      <td>1177</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.042139</td>\n",
       "      <td>12887</td>\n",
       "      <td>1177</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.042174</td>\n",
       "      <td>12888</td>\n",
       "      <td>1177</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.039024</td>\n",
       "      <td>12889</td>\n",
       "      <td>1179</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.039024</td>\n",
       "      <td>12889</td>\n",
       "      <td>1179</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.037459</td>\n",
       "      <td>12890</td>\n",
       "      <td>1180</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.035889</td>\n",
       "      <td>12891</td>\n",
       "      <td>1181</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.032706</td>\n",
       "      <td>12892</td>\n",
       "      <td>1183</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.031097</td>\n",
       "      <td>12892</td>\n",
       "      <td>1184</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.031097</td>\n",
       "      <td>12892</td>\n",
       "      <td>1184</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.029484</td>\n",
       "      <td>12892</td>\n",
       "      <td>1185</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.027869</td>\n",
       "      <td>12892</td>\n",
       "      <td>1186</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>12892</td>\n",
       "      <td>1188</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>12892</td>\n",
       "      <td>1188</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.019753</td>\n",
       "      <td>12892</td>\n",
       "      <td>1191</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.019753</td>\n",
       "      <td>12892</td>\n",
       "      <td>1191</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.019753</td>\n",
       "      <td>12892</td>\n",
       "      <td>1191</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.016488</td>\n",
       "      <td>12892</td>\n",
       "      <td>1193</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.014851</td>\n",
       "      <td>12892</td>\n",
       "      <td>1194</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>12892</td>\n",
       "      <td>1195</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>12892</td>\n",
       "      <td>1197</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>12892</td>\n",
       "      <td>1197</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>12892</td>\n",
       "      <td>1197</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>12892</td>\n",
       "      <td>1197</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>12892</td>\n",
       "      <td>1198</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.006628</td>\n",
       "      <td>12892</td>\n",
       "      <td>1199</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>12892</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>12892</td>\n",
       "      <td>1202</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>12892</td>\n",
       "      <td>1202</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>12892</td>\n",
       "      <td>1202</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12892</td>\n",
       "      <td>1203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold     score     TP    FP     FN    TN\n",
       "0        0.00  0.157286      1     0  12891  1203\n",
       "1        0.02  0.159368    224     2  12668  1201\n",
       "2        0.04  0.175220   2077    49  10815  1154\n",
       "3        0.06  0.199084   4859   182   8033  1021\n",
       "4        0.08  0.226240   7423   352   5469   851\n",
       "5        0.10  0.248428   9498   551   3394   652\n",
       "6        0.12  0.256775  10911   734   1981   469\n",
       "7        0.14  0.243053  11724   875   1168   328\n",
       "8        0.16  0.224555  12150   957    742   246\n",
       "9        0.18  0.209584  12395  1004    497   199\n",
       "10       0.20  0.175044  12552  1055    340   148\n",
       "11       0.22  0.139657  12683  1097    209   106\n",
       "12       0.24  0.106169  12775  1129    117    74\n",
       "13       0.26  0.076104  12831  1153     61    50\n",
       "14       0.28  0.065523  12855  1161     37    42\n",
       "15       0.30  0.056782  12863  1167     29    36\n",
       "16       0.32  0.050996  12872  1171     20    32\n",
       "17       0.34  0.049600  12876  1172     16    31\n",
       "18       0.36  0.043513  12881  1176     11    27\n",
       "19       0.38  0.042071  12885  1177      7    26\n",
       "20       0.40  0.042139  12887  1177      5    26\n",
       "21       0.42  0.042174  12888  1177      4    26\n",
       "22       0.44  0.039024  12889  1179      3    24\n",
       "23       0.46  0.039024  12889  1179      3    24\n",
       "24       0.48  0.037459  12890  1180      2    23\n",
       "25       0.50  0.035889  12891  1181      1    22\n",
       "26       0.52  0.032706  12892  1183      0    20\n",
       "27       0.54  0.031097  12892  1184      0    19\n",
       "28       0.56  0.031097  12892  1184      0    19\n",
       "29       0.58  0.029484  12892  1185      0    18\n",
       "30       0.60  0.027869  12892  1186      0    17\n",
       "31       0.62  0.024631  12892  1188      0    15\n",
       "32       0.64  0.024631  12892  1188      0    15\n",
       "33       0.66  0.019753  12892  1191      0    12\n",
       "34       0.68  0.019753  12892  1191      0    12\n",
       "35       0.70  0.019753  12892  1191      0    12\n",
       "36       0.72  0.016488  12892  1193      0    10\n",
       "37       0.74  0.014851  12892  1194      0     9\n",
       "38       0.76  0.013212  12892  1195      0     8\n",
       "39       0.78  0.009926  12892  1197      0     6\n",
       "40       0.80  0.009926  12892  1197      0     6\n",
       "41       0.82  0.009926  12892  1197      0     6\n",
       "42       0.84  0.009926  12892  1197      0     6\n",
       "43       0.86  0.008278  12892  1198      0     5\n",
       "44       0.88  0.006628  12892  1199      0     4\n",
       "45       0.90  0.004975  12892  1200      0     3\n",
       "46       0.92  0.001661  12892  1202      0     1\n",
       "47       0.94  0.001661  12892  1202      0     1\n",
       "48       0.96  0.001661  12892  1202      0     1\n",
       "49       0.98  0.000000  12892  1203      0     0"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "TP = []\n",
    "FP = []\n",
    "FN = []\n",
    "TN = []\n",
    "for threshold in range(50) :\n",
    "    threshold = threshold / 50\n",
    "    pred = cat_val\n",
    "    pred = np.where(pred >= threshold, 1, 0)\n",
    "    score = f1_score(y_train, pred)\n",
    "    scores.append(score)\n",
    "    TP.append(confusion_matrix(y_train, pred)[0][0])\n",
    "    FN.append(confusion_matrix(y_train, pred)[0][1])\n",
    "    FP.append(confusion_matrix(y_train, pred)[1][0])\n",
    "    TN.append(confusion_matrix(y_train, pred)[1][1])\n",
    "    \n",
    "\n",
    "temp1 = pd.DataFrame(np.linspace(0, 0.98, 50), columns = ['threshold'])\n",
    "temp2 = pd.DataFrame(scores, columns = ['score'])\n",
    "temp3 = pd.DataFrame(TP, columns = ['TP'])\n",
    "temp4 = pd.DataFrame(FP, columns = ['FP'])\n",
    "temp5 = pd.DataFrame(FN, columns = ['FN'])\n",
    "temp6 = pd.DataFrame(TN, columns = ['TN'])\n",
    "scores = pd.concat([temp1, temp2, temp3, temp4, temp5, temp6], axis = 1)\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "bfe67406-00a2-4121-94a6-4ab11b6ac51d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.157286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.157636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.159368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.166180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.175220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.186376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.199084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.211991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.226240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.237731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.248428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.250464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.256775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.253485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.243053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.233431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.224555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.216915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.209584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.192825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.175044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.152978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.139657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.119588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.106169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.086438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.076104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.070933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.065523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.059561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.056782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.050834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.050996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.051037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.049600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.044944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.043513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.042037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.042071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.042139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.042139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.042174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.042174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.039024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.039024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.039024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.039024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.037459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.037459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.035860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.035889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold     score\n",
       "0        0.00  0.157286\n",
       "1        0.01  0.157636\n",
       "2        0.02  0.159368\n",
       "3        0.03  0.166180\n",
       "4        0.04  0.175220\n",
       "5        0.05  0.186376\n",
       "6        0.06  0.199084\n",
       "7        0.07  0.211991\n",
       "8        0.08  0.226240\n",
       "9        0.09  0.237731\n",
       "10       0.10  0.248428\n",
       "11       0.11  0.250464\n",
       "12       0.12  0.256775\n",
       "13       0.13  0.253485\n",
       "14       0.14  0.243053\n",
       "15       0.15  0.233431\n",
       "16       0.16  0.224555\n",
       "17       0.17  0.216915\n",
       "18       0.18  0.209584\n",
       "19       0.19  0.192825\n",
       "20       0.20  0.175044\n",
       "21       0.21  0.152978\n",
       "22       0.22  0.139657\n",
       "23       0.23  0.119588\n",
       "24       0.24  0.106169\n",
       "25       0.25  0.086438\n",
       "26       0.26  0.076104\n",
       "27       0.27  0.070933\n",
       "28       0.28  0.065523\n",
       "29       0.29  0.059561\n",
       "30       0.30  0.056782\n",
       "31       0.31  0.050834\n",
       "32       0.32  0.050996\n",
       "33       0.33  0.051037\n",
       "34       0.34  0.049600\n",
       "35       0.35  0.044944\n",
       "36       0.36  0.043513\n",
       "37       0.37  0.042037\n",
       "38       0.38  0.042071\n",
       "39       0.39  0.042139\n",
       "40       0.40  0.042139\n",
       "41       0.41  0.042174\n",
       "42       0.42  0.042174\n",
       "43       0.43  0.039024\n",
       "44       0.44  0.039024\n",
       "45       0.45  0.039024\n",
       "46       0.46  0.039024\n",
       "47       0.47  0.037459\n",
       "48       0.48  0.037459\n",
       "49       0.49  0.035860\n",
       "50       0.50  0.035889"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for threshold in range(100) :\n",
    "    threshold = threshold / 100\n",
    "    pred = cat_val\n",
    "    pred = np.where(pred >= threshold, 1, 0)\n",
    "    score = f1_score(y_train, pred)\n",
    "    scores.append(score)\n",
    "\n",
    "temp1 = pd.DataFrame(np.linspace(0, 0.99, 100), columns = ['threshold'])\n",
    "temp2 = pd.DataFrame(scores, columns = ['score'])\n",
    "scores = pd.concat([temp1, temp2], axis = 1)\n",
    "scores.loc[: 50, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "33b40017-ae2c-4864-95c5-eb3d1af93766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.256775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold     score\n",
       "12       0.12  0.256775"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.loc[scores['score'] == scores['score'].max(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "3ad08e44-f263-4d47-acb8-7f434a36855a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 5510, 1: 531})\n"
     ]
    }
   ],
   "source": [
    "answer = np.zeros(cat_test.shape[0])\n",
    "\n",
    "for i in range(cat_test.shape[0]) :\n",
    "  if cat_test[i] >= 0.147 :\n",
    "    answer[i] = 1\n",
    "    \n",
    "answer = answer.astype('int64')\n",
    "print(Counter(answer))\n",
    "\n",
    "# CAT, LGB : 0.144 -> 523개, 0.243522\n",
    "# CAT, RF : 0.147 -> 531개, 0.256775\n",
    "# CAT, GBM : 0.11 -> 505개, 0.24704\n",
    "# CAT, HGB : 0.154 -> 521개, 0.253708\n",
    "# CAT, RF, HGB : 0.151 -> 529개, 0.254096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "04471b8f-0ba7-44b9-af93-325951f36686",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_preds = answer\n",
    "submission = pd.read_csv('/home/studio-lab-user/MYDATA/Construction Machine Oil/open/sample_submission.csv')\n",
    "submission['Y_LABEL'] = submission_preds\n",
    "submission.to_csv('/home/studio-lab-user/MYDATA/Construction Machine Oil/결과/CAT_RF.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e2a18-f8e1-40d4-bef4-6f78b0c03f71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6d35e2-8bdc-4f65-850b-eb4e47ce5d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607b0091-c8ce-4ca9-a29f-78ab7ef29bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4102530-3bbf-4828-8419-637cddf0b2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723ef963-de0a-4974-9453-6e9eced04a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aa80f4-51d1-4284-be2f-e76814c0b899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aec3edf-87b6-41a2-bd68-4fbe343425f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442e999c-1982-430a-96f1-c9005c7c7cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d18cda-33be-47b4-964a-18de03affc89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e258473-4c23-466a-85dc-441bf940299c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a8a23c-a8e5-4ac7-ac32-8fb0d76108a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a67e18-a229-4787-8707-08f81c44d8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69066a3-5a0a-4c79-9679-7b16e40d16ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a68a4b0-d2d0-4cf9-8a11-6a6ee8fba4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8209b6-c33b-4f0d-a4a0-5eff5cd3ecad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a3a44-b705-4bb0-9eb2-afb546f2c50b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b19b1a-2667-4f04-b28a-9c9b50eca3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c45e9f-d10b-46b5-a3e8-742deecd5edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10841864-d9df-4c5a-b60c-69760d53ea85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77836d99-0d49-427c-a272-60d78b2b4e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3857daf2-19ca-45a3-a22d-dfbbd0c81db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78c354c-bc14-4cd7-8e31-5d4214769f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4db33af-a12e-4c9e-88db-e4f270390b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47beac15-5443-4aee-a6e6-ef9771191898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015e3382-b19e-4e26-9473-a39463e11c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c433b2-bbb7-44f5-b49a-683a5678a627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a90c71-c15e-4b76-9da3-4eddc45af98e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5f92f2-9fed-4616-aa2a-3a6c9d870dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4160c5-e5c6-4d82-ab5f-b99afb350960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af774451-fbc3-4506-a9b1-f1ee05e1346c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d48c7-16d5-47ea-9bc7-4cc2ff4fe67e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f16194-fd11-4773-a6e5-02aeebad3a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7208db8e-e628-417c-8398-50d26c248b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89ba409-11e9-405b-ad09-ecf075065c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdb9f50-7758-4eaa-9fe5-c36377ca9889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8810d9-c1a6-4cdc-b905-052a04b9d507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9233a6fa-44fb-4092-bd34-0d36683584b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8d5094-8cf0-463a-81dd-42cc9547d195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "zWzj1-XWrnE0"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
